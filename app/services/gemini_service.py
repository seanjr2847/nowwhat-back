import json
import asyncio
from typing import List, Dict, Optional
import google.generativeai as genai
from app.core.config import settings
from app.schemas.nowwhat import IntentOption
from app.schemas.questions import Question, Option
from app.prompts.intent_analysis import get_intent_analysis_prompt, IntentAnalysisResponse
from app.prompts.search_prompts import get_search_prompt, SearchResponse
from app.prompts.checklist_prompts import ChecklistResponse
from app.prompts.questions_generation import get_questions_generation_prompt, QuestionsListResponse
from app.prompts.enhanced_prompts import get_enhanced_knowledge_prompt
import logging
import uuid
from dataclasses import dataclass
from typing import Any
from pydantic import BaseModel

logger = logging.getLogger(__name__)
# Gemini ì„œë¹„ìŠ¤ ë””ë²„ê¹…ì„ ìœ„í•´ ì„ì‹œë¡œ DEBUG ë ˆë²¨ ì„¤ì •
logger.setLevel(logging.DEBUG)

# Pydantic ëª¨ë¸ë“¤ì€ ì´ì œ í”„ë¡¬í”„íŠ¸ íŒŒì¼ì—ì„œ import

@dataclass
class SearchResult:
    """Gemini API ê²€ìƒ‰ ê²°ê³¼"""
    query: str
    content: str
    sources: List[str]
    success: bool
    error_message: Optional[str] = None
# ì½˜ì†” í•¸ë“¤ëŸ¬ ì¶”ê°€ (ì´ë¯¸ ìˆë‹¤ë©´ ë¬´ì‹œë¨)
if not logger.handlers:
    console_handler = logging.StreamHandler()
    console_handler.setLevel(logging.DEBUG)
    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    logger.addHandler(console_handler)

# Gemini API ì„¤ì •
if settings.GEMINI_API_KEY:
    genai.configure(api_key=settings.GEMINI_API_KEY)
    logger.info(f"Gemini API configured with key: {settings.GEMINI_API_KEY[:10]}...{settings.GEMINI_API_KEY[-4:]}")
else:
    logger.error("GEMINI_API_KEY not found in settings")

class GeminiService:
    def __init__(self):
        if not settings.GEMINI_API_KEY:
            logger.error("Cannot initialize GeminiService: GEMINI_API_KEY not set")
            raise ValueError("GEMINI_API_KEY not configured")
        
        self.model = genai.GenerativeModel(settings.GEMINI_MODEL)
        logger.info(f"GeminiService initialized with model: {settings.GEMINI_MODEL}")
        
    async def analyze_intent(self, goal: str, user_country: Optional[str] = None) -> List[IntentOption]:
        """ì‚¬ìš©ì ëª©í‘œë¥¼ ë¶„ì„í•˜ì—¬ 4ê°€ì§€ ì˜ë„ ì˜µì…˜ ìƒì„±"""
        try:
            prompt = self._create_prompt(goal, user_country)
            
            # 3íšŒ ì¬ì‹œë„ ë¡œì§
            for attempt in range(3):
                try:
                    response = await self._call_gemini_api(prompt)
                    intents = self._parse_response(response)
                    
                    if len(intents) == 4:
                        return intents
                    else:
                        logger.warning(f"Gemini returned {len(intents)} intents instead of 4 (attempt {attempt + 1})")
                        
                except Exception as e:
                    logger.error(f"Gemini API call failed (attempt {attempt + 1}): {str(e)}")
                    if attempt < 2:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì§€ì—° í›„ ì¬ì‹œë„
                        await asyncio.sleep(2 ** attempt)  # exponential backoff
                    
            # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ í…œí”Œë¦¿ ë°˜í™˜
            logger.warning("All Gemini API attempts failed, using default template")
            return self._get_default_template()
            
        except Exception as e:
            logger.error(f"Intent analysis failed: {str(e)}")
            return self._get_default_template()

    async def generate_questions(
        self, 
        goal: str, 
        intent_title: str, 
        user_country: Optional[str] = None
    ) -> List[Question]:
        """ì„ íƒëœ ì˜ë„ì— ë”°ë¥¸ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± (3-5ê°œ)"""
        try:
            prompt = self._create_questions_prompt(goal, intent_title, user_country)
            
            # 3íšŒ ì¬ì‹œë„ ë¡œì§
            for attempt in range(3):
                try:
                    response = await self._call_gemini_api(prompt)
                    questions = self._parse_questions_response(response)
                    
                    if 3 <= len(questions) <= 5:
                        return questions
                    else:
                        logger.warning(f"Gemini returned {len(questions)} questions instead of 3-5 (attempt {attempt + 1})")
                        
                except Exception as e:
                    logger.error(f"Gemini questions API call failed (attempt {attempt + 1}): {str(e)}")
                    if attempt < 2:
                        await asyncio.sleep(2 ** attempt)
                    
            # ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ì‹œ ìºì‹œëœ ì§ˆë¬¸ í…œí”Œë¦¿ ë°˜í™˜
            logger.warning("All Gemini questions API attempts failed, using cached template")
            return self._get_cached_questions_template(intent_title)
            
        except Exception as e:
            logger.error(f"Question generation failed: {str(e)}")
            return self._get_cached_questions_template(intent_title)

    def _create_questions_prompt(self, goal: str, intent_title: str, user_country: Optional[str] = None) -> str:
        """ì§ˆë¬¸ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        country_context = self._get_country_context(user_country)
        
        return get_questions_generation_prompt(
            goal=goal,
            intent_title=intent_title,
            user_country=user_country or "ì •ë³´ ì—†ìŒ",
            country_context=country_context
        )

    def _get_country_context(self, user_country: Optional[str]) -> str:
        """êµ­ê°€ë³„ ë§ì¶¤ ì»¨í…ìŠ¤íŠ¸"""
        contexts = {
            "KR": "í•œêµ­ ê±°ì£¼ì ê¸°ì¤€, í•œêµ­ ë¬¸í™”ì™€ í™˜ê²½ ê³ ë ¤",
            "US": "ë¯¸êµ­ ê±°ì£¼ì ê¸°ì¤€, ë¯¸êµ­ ë¬¸í™”ì™€ í™˜ê²½ ê³ ë ¤", 
            "JP": "ì¼ë³¸ ê±°ì£¼ì ê¸°ì¤€, ì¼ë³¸ ë¬¸í™”ì™€ í™˜ê²½ ê³ ë ¤",
            "CN": "ì¤‘êµ­ ê±°ì£¼ì ê¸°ì¤€, ì¤‘êµ­ ë¬¸í™”ì™€ í™˜ê²½ ê³ ë ¤"
        }
        return contexts.get(user_country, "ê¸€ë¡œë²Œ ê¸°ì¤€")

    def _parse_questions_response(self, response: str) -> List[Question]:
        """Gemini ì§ˆë¬¸ ì‘ë‹µ íŒŒì‹±"""
        try:
            # ì‘ë‹µì´ ë¹„ì–´ìˆëŠ”ì§€ í™•ì¸
            if not response or not response.strip():
                logger.warning("Gemini returned empty response")
                raise ValueError("Empty response from Gemini")
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            response = response.strip()
            logger.debug(f"Raw Gemini response: {response[:200]}...")  # ë””ë²„ê¹…ìš©
            
            if response.startswith("```json"):
                response = response[7:]
            if response.endswith("```"):
                response = response[:-3]
            response = response.strip()
            
            # ë¹ˆ ì‘ë‹µ ì¬í™•ì¸
            if not response:
                logger.warning("Response became empty after cleaning")
                raise ValueError("Empty response after cleaning")
            
            questions_data = json.loads(response)
            
            if not isinstance(questions_data, list):
                raise ValueError("Response is not a list")
                
            questions = []
            for item in questions_data:
                # í•„ìˆ˜ í•„ë“œ í™•ì¸
                if not all(key in item for key in ["id", "text", "type", "required"]):
                    raise ValueError("Missing required fields in question")
                
                # options ì²˜ë¦¬
                options = None
                if item["type"] == "multiple" and "options" in item:
                    options = [
                        Option(
                            id=opt["id"],
                            text=opt["text"], 
                            value=opt["value"]
                        ) for opt in item["options"]
                    ]
                
                questions.append(Question(
                    id=item["id"],
                    text=item["text"],
                    type=item["type"],
                    options=options,
                    required=item["required"]
                ))
                
            return questions
            
        except json.JSONDecodeError as e:
            logger.error(f"JSON decode error: {str(e)}, Response: '{response[:500]}'")
            raise Exception(f"Failed to parse Gemini questions response: Invalid JSON - {str(e)}")
        except Exception as e:
            logger.error(f"Questions parsing error: {str(e)}, Response: '{response[:500] if 'response' in locals() else 'N/A'}'")
            raise Exception(f"Failed to parse Gemini questions response: {str(e)}")

    def _get_cached_questions_template(self, intent_title: str) -> List[Question]:
        """ì˜ë„ë³„ ìºì‹œëœ ì§ˆë¬¸ í…œí”Œë¦¿"""
        templates = {
            "ì—¬í–‰ ê³„íš": [
                Question(
                    id="q_duration",
                    text="ì—¬í–‰ ê¸°ê°„ì€ ì–¼ë§ˆë‚˜ ë˜ë‚˜ìš”?",
                    type="multiple",
                    options=[
                        Option(id="opt_3days", text="2ë°• 3ì¼", value="3days"),
                        Option(id="opt_5days", text="4ë°• 5ì¼", value="5days"),
                        Option(id="opt_1week", text="1ì£¼ì¼", value="1week"),
                        Option(id="opt_longer", text="1ì£¼ì¼ ì´ìƒ", value="longer")
                    ],
                    required=True
                ),
                Question(
                    id="q_companions",
                    text="ëˆ„êµ¬ì™€ í•¨ê»˜ ê°€ì‹œë‚˜ìš”?",
                    type="multiple",
                    options=[
                        Option(id="opt_alone", text="í˜¼ì", value="alone"),
                        Option(id="opt_couple", text="ì—°ì¸/ë°°ìš°ìì™€", value="couple"),
                        Option(id="opt_family", text="ê°€ì¡±ê³¼", value="family"),
                        Option(id="opt_friends", text="ì¹œêµ¬ë“¤ê³¼", value="friends")
                    ],
                    required=True
                ),
                Question(
                    id="q_activities",
                    text="ì£¼ë¡œ í•˜ê³  ì‹¶ì€ í™œë™ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    type="multiple",
                    options=[
                        Option(id="opt_sightseeing", text="ê´€ê´‘/ëª…ì†Œ íƒë°©", value="sightseeing"),
                        Option(id="opt_food", text="ë§›ì§‘ íƒë°©", value="food"),
                        Option(id="opt_shopping", text="ì‡¼í•‘", value="shopping"),
                        Option(id="opt_culture", text="ë¬¸í™” ì²´í—˜", value="culture")
                    ],
                    required=True
                )
            ],
            "ê³„íš ì„¸ìš°ê¸°": [
                Question(
                    id="q_timeline",
                    text="ì–¸ì œê¹Œì§€ ê³„íšì„ ì™„ì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                    type="multiple",
                    options=[
                        Option(id="opt_1week", text="1ì£¼ì¼ ë‚´", value="1week"),
                        Option(id="opt_1month", text="1ë‹¬ ë‚´", value="1month"),
                        Option(id="opt_3months", text="3ë‹¬ ë‚´", value="3months"),
                        Option(id="opt_flexible", text="ìœ ì—°í•˜ê²Œ", value="flexible")
                    ],
                    required=True
                ),
                Question(
                    id="q_priority",
                    text="ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒì€?",
                    type="multiple",
                    options=[
                        Option(id="opt_time", text="ì‹œê°„ íš¨ìœ¨ì„±", value="time"),
                        Option(id="opt_cost", text="ë¹„ìš© ì ˆì•½", value="cost"),
                        Option(id="opt_quality", text="í’ˆì§ˆ/ë§Œì¡±ë„", value="quality"),
                        Option(id="opt_convenience", text="í¸ì˜ì„±", value="convenience")
                    ],
                    required=True
                )
            ]
        }
        
        return templates.get(intent_title, self._get_default_questions_template())

    def _get_default_questions_template(self) -> List[Question]:
        """ê¸°ë³¸ ì§ˆë¬¸ í…œí”Œë¦¿"""
        return [
            Question(
                id="q_when",
                text="ì–¸ì œê¹Œì§€ ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                type="multiple",
                options=[
                    Option(id="opt_1week", text="1ì£¼ì¼ ë‚´", value="1week"),
                    Option(id="opt_1month", text="1ë‹¬ ë‚´", value="1month"),
                    Option(id="opt_3months", text="3ë‹¬ ë‚´", value="3months"),
                    Option(id="opt_6months", text="6ë‹¬ ë‚´", value="6months")
                ],
                required=True
            ),
            Question(
                id="q_resources",
                text="ì´ ëª©í‘œë¥¼ ìœ„í•´ íˆ¬ìí•  ìˆ˜ ìˆëŠ” ìì›ì€?",
                type="multiple", 
                options=[
                    Option(id="opt_time", text="ì£¼ë¡œ ì‹œê°„", value="time"),
                    Option(id="opt_money", text="ì£¼ë¡œ ëˆ", value="money"),
                    Option(id="opt_both", text="ì‹œê°„ê³¼ ëˆ ëª¨ë‘", value="both"),
                    Option(id="opt_minimal", text="ìµœì†Œí•œë§Œ", value="minimal")
                ],
                required=True
            ),
            Question(
                id="q_priority",
                text="ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒì€?",
                type="multiple",
                options=[
                    Option(id="opt_speed", text="ë¹ ë¥¸ ë‹¬ì„±", value="speed"),
                    Option(id="opt_quality", text="ë†’ì€ í’ˆì§ˆ", value="quality"),
                    Option(id="opt_cost", text="ë¹„ìš© ì ˆì•½", value="cost"),
                    Option(id="opt_balance", text="ê· í˜•ì¡íŒ ì ‘ê·¼", value="balance")
                ],
                required=True
            )
        ]
    
    def _create_prompt(self, goal: str, user_country: Optional[str] = None) -> str:
        """Gemini APIìš© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        country_info = f"ì‚¬ìš©ì ê±°ì£¼ êµ­ê°€: {user_country}" if user_country else ""
        return get_intent_analysis_prompt(goal, country_info)

    async def _call_gemini_api_with_search(self, prompt: str) -> str:
        """Gemini API í˜¸ì¶œ (ê³µì‹ Google Search ê¸°ëŠ¥ ì‚¬ìš©)"""
        try:
            logger.debug(f"Sending search prompt to Gemini (length: {len(prompt)} chars)")
            
            # ê³µì‹ Google Search grounding êµ¬í˜„ + Structured Output
            try:
                # Google Search ë„êµ¬ ì„¤ì • (ê³µì‹ ë°©ë²•)
                search_tool = genai.protos.Tool(
                    google_search_retrieval=genai.protos.GoogleSearchRetrieval()
                )
                
                logger.debug("Using Google Search grounding tool with structured output")
                
                # SearchResponseë¥¼ Gemini í˜¸í™˜ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜
                response_schema = self._create_gemini_compatible_schema()
                
                response = await asyncio.to_thread(
                    self.model.generate_content,
                    prompt,
                    tools=[search_tool],
                    generation_config=genai.types.GenerationConfig(
                        max_output_tokens=8192,
                        temperature=0.7,
                        top_p=0.8,
                        top_k=40,
                        response_mime_type="application/json",
                        response_schema=response_schema
                    )
                )
                
                logger.debug("Google Search grounding with structured output completed")
                
            except Exception as tool_error:
                logger.warning(f"Google Search grounding failed: {tool_error}")
                logger.debug(f"Error type: {type(tool_error).__name__}")
                logger.info("Trying alternative Google Search implementation")
                
                try:
                    # ëŒ€ì•ˆì  êµ¬í˜„ (ìµœì‹  SDK) + Structured Output
                    from google.generativeai.types import Tool
                    
                    # ìµœì‹  SDKì˜ GoogleSearch ë„êµ¬
                    search_tool = Tool(
                        google_search_retrieval={}
                    )
                    
                    # SearchResponseë¥¼ JSON Schemaë¡œ ë³€í™˜
                    response_schema = SearchResponse.model_json_schema()
                    
                    response = await asyncio.to_thread(
                        self.model.generate_content,
                        prompt,
                        tools=[search_tool],
                        generation_config=genai.types.GenerationConfig(
                            max_output_tokens=8192,
                            temperature=0.7,
                            top_p=0.8,
                            top_k=40,
                            response_mime_type="application/json",
                            response_schema=response_schema
                        )
                    )
                    
                except Exception as alt_error:
                    logger.warning(f"Alternative Google Search failed: {alt_error}")
                    logger.debug(f"Alternative error type: {type(alt_error).__name__}")
                    logger.info("Using enhanced knowledge-based prompt")
                    
                    # ì›¹ ê²€ìƒ‰ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ê²½ìš°, ìµœì‹  ì •ë³´ ìš”ì²­ í”„ë¡¬í”„íŠ¸ + Structured Output
                    enhanced_prompt = get_enhanced_knowledge_prompt(prompt)

                    # SearchResponseë¥¼ JSON Schemaë¡œ ë³€í™˜
                    response_schema = SearchResponse.model_json_schema()
                    
                    response = await asyncio.to_thread(
                        self.model.generate_content,
                        enhanced_prompt,
                        generation_config=genai.types.GenerationConfig(
                            max_output_tokens=8192,
                            temperature=0.7,
                            top_p=0.8,
                            top_k=40,
                            response_mime_type="application/json",
                            response_schema=response_schema
                        )
                    )
            
            # ì‘ë‹µ ì²˜ë¦¬
            if not response:
                logger.error("Gemini returned None response")
                raise Exception("Gemini returned None response")
            
            # grounding metadata í™•ì¸ (ì›¹ ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆëŠ”ì§€)
            if hasattr(response, 'candidates') and response.candidates:
                for candidate in response.candidates:
                    if hasattr(candidate, 'grounding_metadata'):
                        logger.info("Response includes grounding metadata (web search results)")
                        if hasattr(candidate.grounding_metadata, 'search_entry_point'):
                            logger.debug(f"Search entry point: {candidate.grounding_metadata.search_entry_point}")
                        if hasattr(candidate.grounding_metadata, 'grounding_chunks'):
                            logger.debug(f"Found {len(candidate.grounding_metadata.grounding_chunks)} grounding chunks")
            
            # í…ìŠ¤íŠ¸ ì¶”ì¶œ
            if not hasattr(response, 'text'):
                logger.debug("Extracting text from candidates...")
                if hasattr(response, 'candidates') and response.candidates:
                    for candidate in response.candidates:
                        if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                            for part in candidate.content.parts:
                                if hasattr(part, 'text') and part.text:
                                    response_text = part.text
                                    break
                    else:
                        raise Exception("No text found in candidates")
                else:
                    raise Exception("No candidates in response")
            else:
                response_text = response.text
            
            logger.debug(f"Gemini search response received (length: {len(response_text) if response_text else 0})")
            
            if not response_text or not response_text.strip():
                logger.error("Gemini returned empty response")
                raise Exception("Gemini returned empty response")
                
            return response_text
            
        except Exception as e:
            logger.error(f"Gemini search API call error: {str(e)}")
            logger.debug(f"Final error type: {type(e).__name__}")
            # ì›¹ ê²€ìƒ‰ ì‹¤íŒ¨ì‹œ ì¼ë°˜ APIë¡œ í´ë°±
            logger.info("Falling back to regular Gemini API without search")
            return await self._call_gemini_api(prompt)
    
    async def _call_gemini_api(self, prompt: str) -> str:
        """Gemini API í˜¸ì¶œ"""
        try:
            logger.debug(f"Sending prompt to Gemini (length: {len(prompt)} chars)")
            response = await asyncio.to_thread(
                self.model.generate_content, 
                prompt,
                generation_config=genai.types.GenerationConfig(
                    max_output_tokens=8192,  # ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±ì„ ìœ„í•´ ë” í° í† í° ìˆ˜ ì„¤ì •
                    temperature=0.7,
                    top_p=0.8,
                    top_k=40
                )
            )
            
            # ì‘ë‹µ ìƒíƒœ í™•ì¸
            if not response:
                logger.error("Gemini returned None response")
                raise Exception("Gemini returned None response")
            
            # ì‘ë‹µ ê°ì²´ êµ¬ì¡° í™•ì¸
            logger.debug(f"Gemini response type: {type(response)}")
            logger.debug(f"Gemini response attributes: {dir(response)}")
            
            # Safety rating ë° finish reason í™•ì¸
            if hasattr(response, 'candidates') and response.candidates:
                for i, candidate in enumerate(response.candidates):
                    finish_reason = candidate.finish_reason if hasattr(candidate, 'finish_reason') else 'N/A'
                    logger.debug(f"Candidate {i} finish_reason: {finish_reason}")
                    
                    # finish_reason í•´ì„
                    if finish_reason == 2:
                        logger.warning("Response was truncated due to MAX_TOKENS limit - consider increasing max_output_tokens")
                    elif finish_reason == 3:
                        logger.warning("Response was blocked by safety filters")
                    elif finish_reason == 4:
                        logger.warning("Response was blocked due to recitation concerns")
                    
                    if hasattr(candidate, 'safety_ratings'):
                        logger.debug(f"Candidate {i} safety_ratings: {candidate.safety_ratings}")
            
            if not hasattr(response, 'text'):
                logger.error(f"Gemini response has no text attribute: {type(response)}")
                # ëŒ€ì•ˆìœ¼ë¡œ candidatesì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„
                if hasattr(response, 'candidates') and response.candidates:
                    for candidate in response.candidates:
                        if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                            for part in candidate.content.parts:
                                if hasattr(part, 'text') and part.text:
                                    logger.debug(f"Found text in candidate.content.parts: {part.text[:100]}...")
                                    response_text = part.text
                                    break
                    else:
                        raise Exception("Gemini response has no text attribute and no text in candidates")
                else:
                    raise Exception("Gemini response has no text attribute")
            else:
                response_text = response.text
            
            logger.debug(f"Raw Gemini response (length: {len(response_text) if response_text else 0}): '{response_text}'")
            
            if not response_text or not response_text.strip():
                logger.error("Gemini returned empty or whitespace-only response")
                raise Exception("Gemini returned empty response")
                
            return response_text
            
        except Exception as e:
            logger.error(f"Gemini API call error details: {str(e)}")
            raise Exception(f"Gemini API call failed: {str(e)}")
    
    def _parse_response(self, response: str) -> List[IntentOption]:
        """Gemini ì‘ë‹µ íŒŒì‹±"""
        try:
            logger.debug(f"Intent parsing - Raw response: '{response[:200]}...' (total length: {len(response)})")
            
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            response = response.strip()
            logger.debug(f"Intent parsing - After strip: '{response[:200]}...'")
            
            if response.startswith("```json"):
                response = response[7:]
                logger.debug("Intent parsing - Removed ```json prefix")
            if response.endswith("```"):
                response = response[:-3]
                logger.debug("Intent parsing - Removed ``` suffix")
            response = response.strip()
            
            logger.debug(f"Intent parsing - Final JSON to parse: '{response[:200]}...'")
            
            if not response:
                logger.error("Intent parsing - Response became empty after cleaning")
                raise ValueError("Empty response after cleaning")
            
            intents_data = json.loads(response)
            logger.debug(f"Intent parsing - Successfully parsed JSON with {len(intents_data) if isinstance(intents_data, list) else 'non-list'} items")
            
            if not isinstance(intents_data, list):
                raise ValueError("Response is not a list")
                
            intents = []
            for item in intents_data:
                if not all(key in item for key in ["title", "description", "icon"]):
                    raise ValueError("Missing required fields in intent")
                    
                intents.append(IntentOption(
                    title=item["title"],
                    description=item["description"],
                    icon=item["icon"]
                ))
                
            return intents
            
        except Exception as e:
            raise Exception(f"Failed to parse Gemini response: {str(e)}")
    
    def _get_default_template(self) -> List[IntentOption]:
        """ê¸°ë³¸ ì˜ë„ í…œí”Œë¦¿"""
        return [
            IntentOption(
                title="ê³„íš ì„¸ìš°ê¸°",
                description="ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê¸° ìœ„í•œ êµ¬ì²´ì ì¸ ê³„íšì„ ì„¸ìš°ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                icon="ğŸ“‹"
            ),
            IntentOption(
                title="ì¤€ë¹„í•˜ê¸°",
                description="í•„ìš”í•œ ê²ƒë“¤ì„ ì¤€ë¹„í•˜ê³  ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ë§Œë“¤ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                icon="âœ…"
            ),
            IntentOption(
                title="ì •ë³´ ì°¾ê¸°",
                description="ê´€ë ¨ëœ ì •ë³´ë¥¼ ì¡°ì‚¬í•˜ê³  ì•Œì•„ë³´ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                icon="ğŸ”"
            ),
            IntentOption(
                title="ë°”ë¡œ ì‹œì‘í•˜ê¸°",
                description="ì§€ê¸ˆ ë‹¹ì¥ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” ë°©ë²•ì„ ì•Œê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                icon="ğŸš€"
            )
        ]
    
    async def parallel_search(self, queries: List[str]) -> List[SearchResult]:
        """ì—¬ëŸ¬ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰"""
        logger.info("ğŸš€ GEMINI ë³‘ë ¬ ê²€ìƒ‰ ì‹œì‘")
        logger.info(f"   ğŸ“ ìš”ì²­ëœ ì¿¼ë¦¬ ìˆ˜: {len(queries)}ê°œ")
        
        if not queries:
            logger.warning("âš ï¸  ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return []
        
        # ì¿¼ë¦¬ ë‚´ìš© ë¡œê¹…
        for i, query in enumerate(queries[:5]):  # ì²˜ìŒ 5ê°œë§Œ ë¡œê¹…
            logger.info(f"   ğŸ” ì¿¼ë¦¬ {i+1}: {query}")
        if len(queries) > 5:
            logger.info(f"   ... ê·¸ ì™¸ {len(queries) - 5}ê°œ ë”")
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ ìˆ˜ì— ë§ê²Œ ëª¨ë“  ì¿¼ë¦¬ ì²˜ë¦¬ (API ì œí•œ ê³ ë ¤)
        max_concurrent_searches = min(len(queries), settings.MAX_CONCURRENT_SEARCHES)
        limited_queries = queries  # ëª¨ë“  ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ë˜ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì‹¤í–‰
        
        if len(queries) > settings.MAX_CONCURRENT_SEARCHES:
            logger.info(f"ğŸ“¦ {len(queries)}ê°œ ì¿¼ë¦¬ë¥¼ {settings.MAX_CONCURRENT_SEARCHES}ê°œì”© ë°°ì¹˜ë¡œ ì²˜ë¦¬")
        else:
            logger.info(f"âœ… {len(queries)}ê°œ ì¿¼ë¦¬ ëª¨ë‘ ë³‘ë ¬ ì²˜ë¦¬")
        
        try:
            logger.info(f"âš¡ {len(limited_queries)}ê°œ ì¿¼ë¦¬ ì‹¤í–‰ ì¤‘...")
            
            # ëª¨ë“  ì¿¼ë¦¬ë¥¼ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ë³‘ë ¬ ì²˜ë¦¬
            all_results = []
            batch_size = settings.MAX_CONCURRENT_SEARCHES
            
            for i in range(0, len(limited_queries), batch_size):
                batch_queries = limited_queries[i:i+batch_size]
                logger.info(f"ğŸ”„ ë°°ì¹˜ {i//batch_size + 1}: {len(batch_queries)}ê°œ ì¿¼ë¦¬ ì²˜ë¦¬ ì¤‘...")
                
                # ë°°ì¹˜ë³„ ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
                tasks = [self._search_single_query(query) for query in batch_queries]
                batch_results = await asyncio.gather(*tasks, return_exceptions=True)
                all_results.extend(batch_results)
            
            results = all_results
            
            # ì˜ˆì™¸ ì²˜ë¦¬ ë° ê²°ê³¼ ì •ë¦¬
            processed_results = []
            success_queries = []
            failed_queries = []
            
            for i, result in enumerate(results):
                query = limited_queries[i]
                if isinstance(result, Exception):
                    logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨ [{i+1}]: '{query[:50]}...' - {str(result)}")
                    processed_results.append(self._create_error_result(query, str(result)))
                    failed_queries.append(query)
                else:
                    if result.success:
                        logger.info(f"âœ… ê²€ìƒ‰ ì„±ê³µ [{i+1}]: '{query[:50]}...' ({len(result.content)}ì)")
                        success_queries.append(query)
                    else:
                        logger.warning(f"âš ï¸  ê²€ìƒ‰ ì‹¤íŒ¨ [{i+1}]: '{query[:50]}...' - {result.error_message}")
                        failed_queries.append(query)
                    processed_results.append(result)
            
            success_count = len(success_queries)
            failed_count = len(failed_queries)
            
            # ê²°ê³¼ ìš”ì•½
            logger.info("=" * 60)
            logger.info("ğŸ“Š GEMINI ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½")
            logger.info("=" * 60)
            logger.info(f"âœ… ì„±ê³µ: {success_count}ê°œ")
            logger.info(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
            logger.info(f"ğŸ“ˆ ì„±ê³µë¥ : {(success_count/len(limited_queries)*100):.1f}%")
            
            if success_count > 0:
                # ì„±ê³µí•œ ê²€ìƒ‰ ê²°ê³¼ì˜ ë‚´ìš© ê¸¸ì´ í†µê³„
                content_lengths = [len(r.content) for r in processed_results if r.success and r.content]
                if content_lengths:
                    avg_length = sum(content_lengths) / len(content_lengths)
                    min_length = min(content_lengths)
                    max_length = max(content_lengths)
                    logger.info(f"ğŸ“ ì‘ë‹µ ê¸¸ì´: í‰ê·  {avg_length:.0f}ì (ìµœì†Œ {min_length}, ìµœëŒ€ {max_length})")
                
                # ì„±ê³µí•œ ì¿¼ë¦¬ ëª‡ ê°œ ì˜ˆì‹œ
                for query in success_queries[:3]:
                    logger.info(f"   âœ… '{query[:40]}...'")
            
            if failed_count > 0:
                logger.warning(f"âš ï¸  ì‹¤íŒ¨í•œ ì¿¼ë¦¬ {min(3, failed_count)}ê°œ ì˜ˆì‹œ:")
                for query in failed_queries[:3]:
                    logger.warning(f"   âŒ '{query[:40]}...'")
            
            logger.info("=" * 60)
            
            return processed_results
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë³‘ë ¬ ê²€ìƒ‰ ì „ì²´ ì‹¤íŒ¨: {str(e)}")
            logger.error(f"   ğŸ”„ ëª¨ë“  ì¿¼ë¦¬ë¥¼ ì‹¤íŒ¨ ì²˜ë¦¬í•©ë‹ˆë‹¤")
            return [self._create_error_result(query, str(e)) for query in limited_queries]
    
    async def _search_single_query(self, query: str) -> SearchResult:
        """ë‹¨ì¼ ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰ (Gemini ì›¹ ê²€ìƒ‰ ê¸°ëŠ¥ ì‚¬ìš©)"""
        start_time = asyncio.get_event_loop().time()
        logger.debug(f"ğŸ” ë‹¨ì¼ ê²€ìƒ‰ ì‹œì‘: '{query[:50]}...'")
        
        try:
            # Geminiì—ê²Œ ì›¹ ê²€ìƒ‰ì„ í†µí•œ ìµœì‹  ì •ë³´ë¥¼ ìš”ì²­í•˜ëŠ” í”„ë¡¬í”„íŠ¸ ìƒì„± (Structured Output ì‚¬ìš©)
            prompt = get_search_prompt(query)

            # Gemini API í˜¸ì¶œ (ì›¹ ê²€ìƒ‰ í™œì„±í™”)
            response = await self._call_gemini_api_with_search(prompt)
            elapsed = asyncio.get_event_loop().time() - start_time
            
            # ì‘ë‹µ íŒŒì‹±
            result = self._parse_search_response(query, response)
            
            if result.success:
                logger.debug(f"âœ… ê²€ìƒ‰ ì™„ë£Œ ({elapsed:.2f}ì´ˆ): {len(result.content)}ì ì‘ë‹µ")
            else:
                logger.warning(f"âš ï¸  ê²€ìƒ‰ ì‹¤íŒ¨ ({elapsed:.2f}ì´ˆ): {result.error_message}")
            
            return result
                        
        except asyncio.TimeoutError:
            elapsed = asyncio.get_event_loop().time() - start_time
            logger.error(f"â° ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ ({elapsed:.2f}ì´ˆ)")
            logger.error(f"   ì¿¼ë¦¬: '{query[:50]}...'")
            return self._create_error_result(query, f"Search timeout after {elapsed:.2f}s")
        except Exception as e:
            elapsed = asyncio.get_event_loop().time() - start_time
            logger.error(f"ğŸ’¥ ê²€ìƒ‰ ì˜ˆì™¸ ë°œìƒ ({elapsed:.2f}ì´ˆ)")
            logger.error(f"   ì¿¼ë¦¬: '{query[:50]}...'")
            logger.error(f"   ì˜¤ë¥˜: {str(e)}")
            return self._create_error_result(query, f"Exception: {str(e)}")
    
    def _parse_search_response(self, query: str, response: str) -> SearchResult:
        """Gemini ê²€ìƒ‰ ì‘ë‹µ íŒŒì‹± (Structured Output JSON)"""
        try:
            if not response or not response.strip():
                return self._create_error_result(query, "Empty response")
            
            content = response.strip()
            logger.debug(f"Parsing structured output response: {content[:200]}...")
            
            # Structured Outputìœ¼ë¡œ ì¸í•´ ì´ë¯¸ ì˜¬ë°”ë¥¸ JSON í˜•ì‹ì´ì–´ì•¼ í•¨
            try:
                structured_data = json.loads(content)
                logger.info(f"Successfully parsed structured JSON response for query: {query[:50]}...")
                
                # ì‘ë‹µ êµ¬ì¡° ê²€ì¦
                if not isinstance(structured_data, dict):
                    logger.warning("Response is not a dictionary, using as-is")
                    structured_data = {"tips": [content], "contacts": [], "links": [], "price": None, "location": None}
                
                # ë§í¬ ì •ë³´ë¥¼ sourcesë¡œ ë³€í™˜
                sources = []
                if "links" in structured_data and isinstance(structured_data["links"], list):
                    for link in structured_data["links"]:
                        if isinstance(link, dict) and "url" in link:
                            sources.append(link["url"])
                        elif isinstance(link, str):
                            sources.append(link)
                
                return SearchResult(
                    query=query,
                    content=json.dumps(structured_data, ensure_ascii=False),
                    sources=sources,
                    success=True
                )
                
            except json.JSONDecodeError as json_err:
                logger.warning(f"Failed to parse structured JSON for query '{query}': {json_err}")
                logger.warning(f"Raw content: {content[:200]}...")
                
                # Structured Output ì‹¤íŒ¨ì‹œ í´ë°±
                fallback_data = {
                    "tips": [content] if content else ["ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."],
                    "contacts": [],
                    "links": [],
                    "price": None,
                    "location": None
                }
                
                return SearchResult(
                    query=query,
                    content=json.dumps(fallback_data, ensure_ascii=False),
                    sources=[],
                    success=True
                )
            
        except Exception as e:
            logger.error(f"Failed to parse Gemini structured response for query '{query}': {str(e)}")
            return self._create_error_result(query, f"Parse error: {str(e)}")
    
    def _create_error_result(self, query: str, error_message: str) -> SearchResult:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return SearchResult(
            query=query,
            content="",
            sources=[],
            success=False,
            error_message=error_message
        )
    
    def generate_search_queries_from_checklist(
        self,
        checklist_items: List[str],
        goal: str,
        answers: List[Dict[str, Any]]
    ) -> List[str]:
        """ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (Perplexityì™€ ë™ì¼í•œ ì¸í„°í˜ì´ìŠ¤)"""
        
        logger.info("ğŸ¯ GEMINI ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹œì‘")
        logger.info(f"   ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ: {len(checklist_items)}ê°œ")
        logger.info(f"   ğŸ¯ ëª©í‘œ: {goal[:50]}...")
        logger.info(f"   ğŸ’¬ ë‹µë³€: {len(answers)}ê°œ")
        
        # ë‹µë³€ì—ì„œ í•µì‹¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        answer_context = self._extract_answer_context(answers)
        logger.info(f"   ğŸ” ì¶”ì¶œëœ ì»¨í…ìŠ¤íŠ¸: '{answer_context[:80]}...' ({len(answer_context)}ì)")
        
        search_queries = []
        
        # ê° ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œì„ ê¸°ë°˜ìœ¼ë¡œ 1:1 ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        logger.info(f"   ğŸ“ 1:1 ë§¤í•‘ìœ¼ë¡œ ì²˜ë¦¬í•  ì•„ì´í…œ: {len(checklist_items)}ê°œ")
        
        for i, item in enumerate(checklist_items):
            logger.debug(f"   ğŸ” ì•„ì´í…œ {i+1} ì²˜ë¦¬: '{item[:50]}...'")
            
            # ì•„ì´í…œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            core_keywords = self._extract_core_keywords_from_item(item)
            logger.debug(f"      í‚¤ì›Œë“œ: {core_keywords}")
            
            if core_keywords:
                # ë‹¨ì¼ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (1:1 ë§¤í•‘)
                queries = self._generate_item_specific_queries(core_keywords, answer_context)
                logger.debug(f"      ìƒì„±ëœ ì¿¼ë¦¬: {queries}")
                search_queries.extend(queries)  # ì´ì œ í•­ìƒ 1ê°œë§Œ ì¶”ê°€ë¨
            else:
                # í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ì‹œ ê¸°ë³¸ ì¿¼ë¦¬ ìƒì„±
                fallback_query = f"{item[:20]} ë°©ë²•"
                search_queries.append(fallback_query)
                logger.warning(f"      âš ï¸  í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨ â†’ ê¸°ë³¸ ì¿¼ë¦¬: '{fallback_query}'")
        
        # ì¤‘ë³µ ì œê±°í•˜ì§€ ì•Šê³  ìˆœì„œ ìœ ì§€ (1:1 ë§¤í•‘ì„ ìœ„í•´)
        unique_queries = search_queries  # ì¤‘ë³µ ì œê±° ì—†ì´ ëª¨ë“  ì¿¼ë¦¬ ìœ ì§€
        
        logger.info("=" * 50)
        logger.info("ğŸ“ 1:1 ë§¤í•‘ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡")
        logger.info("=" * 50)
        for i, (item, query) in enumerate(zip(checklist_items, unique_queries)):
            logger.info(f"   {i+1:2d}. '{item[:30]}...' â†’ '{query}'")
        logger.info("=" * 50)
        
        logger.info(f"âœ… 1:1 ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: {len(checklist_items)}ê°œ ì•„ì´í…œ â†’ {len(unique_queries)}ê°œ ì¿¼ë¦¬")
        
        if not unique_queries:
            logger.error("ğŸš¨ ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤!")
            logger.error("   ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œì´ ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        elif len(unique_queries) != len(checklist_items):
            logger.warning(f"âš ï¸  ì¿¼ë¦¬ ìˆ˜ ë¶ˆì¼ì¹˜: {len(checklist_items)}ê°œ ì•„ì´í…œ vs {len(unique_queries)}ê°œ ì¿¼ë¦¬")
        
        return unique_queries
    
    def _extract_core_keywords_from_item(self, item: str) -> List[str]:
        """ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œì—ì„œ ê²€ìƒ‰ì— ìœ ìš©í•œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°œì„ ëœ ë²„ì „)"""
        import re
        
        logger.debug(f"í‚¤ì›Œë“œ ì¶”ì¶œ ëŒ€ìƒ: '{item}'")
        
        # í™•ì¥ëœ ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸
        stopwords = [
            'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì˜', 'ì—', 'ì—ì„œ', 'ì™€', 'ê³¼',
            'í•˜ê¸°', 'í•˜ì„¸ìš”', 'í•©ë‹ˆë‹¤', 'ìœ„í•œ', 'ìœ„í•´', 'í†µí•´', 'ëŒ€í•œ', 'í•¨ê»˜',
            'ìˆëŠ”', 'ìˆë‹¤', 'ë˜ëŠ”', 'ë˜ë‹¤', 'ê°™ì€', 'ê°™ì´', 'ëª¨ë“ ', 'ê°ê°',
            'ê²€ìƒ‰', 'ì°¾ê¸°', 'í™•ì¸', 'ì¤€ë¹„', 'ë°©ë²•', 'ì¶”ì²œ', 'ë˜ëŠ”', 'ì£¼ë³€'  # ì¼ë°˜ì ì¸ ë‹¨ì–´ë“¤ ì œì™¸
        ]
        
        # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ íŒ¨í„´ (êµ¬ì²´ì ì¸ ê²ƒë“¤)
        priority_patterns = [
            # êµ¬ì²´ì ì¸ ì„œë¹„ìŠ¤/ë„êµ¬
            r'(?:í™”ìƒ|ì˜¨ë¼ì¸|ëª¨ë°”ì¼)?(?:ì˜ì–´|ì¤‘êµ­ì–´|ì¼ë³¸ì–´|ìŠ¤í˜ì¸ì–´|í”„ë‘ìŠ¤ì–´)(?:ì•±|ì–´í”Œ|ìˆ˜ì—…|ê°•ì˜|êµì¬)',
            r'(?:í™ˆ|ì‹¤ë‚´|í—¬ìŠ¤|í”¼íŠ¸ë‹ˆìŠ¤)?(?:íŠ¸ë ˆì´ë‹|ìš´ë™|ìš”ê°€|í•„ë¼í…ŒìŠ¤)(?:ì•±|ì–´í”Œ|ê¸°êµ¬|ë§¤íŠ¸)',
            r'(?:ì›”ì„¸|ì „ì„¸|ë¶€ë™ì‚°|ë ŒíŠ¸)?(?:ê³„ì•½|ì„ëŒ€|ì¤‘ê°œ|ê´€ë¦¬)(?:ì‚¬ì´íŠ¸|ì•±|ì—…ì²´)',
            r'(?:íˆ¬ì|ì¬í…Œí¬|ì£¼ì‹|í€ë“œ|ì ê¸ˆ)(?:ì•±|í”Œë«í¼|ìƒí’ˆ|ê³„ì¢Œ)',
            
            # êµ¬ì²´ì ì¸ ë¬¼ê±´/ì¬ë£Œ
            r'[ê°€-í£]{2,}(?:ì¬ë£Œ|ë„êµ¬|ì¥ë¹„|ê¸°êµ¬|ìš©í’ˆ|ì œí’ˆ)',
            r'[ê°€-í£]{2,}(?:ì¹´ë“œ|ê³„ì¢Œ|ë³´í—˜|í†µì¥)',
            r'[ê°€-í£]{2,}(?:ë¹„ì|ì—¬ê¶Œ|í•­ê³µí¸|ìˆ™ë°•)',
            
            # êµ¬ì²´ì ì¸ ì„œë¹„ìŠ¤/ê¸°ê´€
            r'[ê°€-í£]{2,}(?:ë³‘ì›|í´ë¦¬ë‹‰|ì„¼í„°|í•™ì›|í•™êµ)',
            r'[ê°€-í£]{2,}(?:ì€í–‰|ì¦ê¶Œ|ë³´í—˜ì‚¬|ì¹´ë“œì‚¬)',
            
            # êµ¬ì²´ì ì¸ í™œë™
            r'[ê°€-í£]{2,}(?:ì‹œí—˜|ìê²©ì¦|ë©´ì ‘|ìƒë‹´)',
            r'[ê°€-í£]{2,}(?:ì—¬í–‰|íˆ¬ì–´|ê´€ê´‘|ë§›ì§‘)',
        ]
        
        keywords = []
        
        # 1. ìš°ì„ ìˆœìœ„ íŒ¨í„´ìœ¼ë¡œ êµ¬ì²´ì  í‚¤ì›Œë“œ ì¶”ì¶œ
        for pattern in priority_patterns:
            matches = re.findall(pattern, item)
            for match in matches:
                if match not in keywords:
                    keywords.append(match)
                    logger.debug(f"  ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ: '{match}'")
        
        # 2. ì˜ì–´ í‚¤ì›Œë“œ ì¶”ì¶œ (ë¸Œëœë“œëª…, ì„œë¹„ìŠ¤ëª… ë“±)
        english_words = re.findall(r'[A-Za-z]{3,}', item)
        for word in english_words:
            if word.lower() not in ['and', 'the', 'for', 'app'] and word not in keywords:
                keywords.append(word)
                logger.debug(f"  ì˜ì–´ í‚¤ì›Œë“œ: '{word}'")
        
        # 3. í•œê¸€ ëª…ì‚¬ ì¶”ì¶œ (3ê¸€ì ì´ìƒ, ë¶ˆìš©ì–´ ì œì™¸)
        korean_words = re.findall(r'[ê°€-í£]{3,}', item)
        for word in korean_words:
            if word not in stopwords and word not in keywords:
                # ì˜ë¯¸ìˆëŠ” ëª…ì‚¬ì¸ì§€ ì¶”ê°€ ê²€ì¦
                if self._is_meaningful_keyword(word):
                    keywords.append(word)
                    logger.debug(f"  í•œê¸€ í‚¤ì›Œë“œ: '{word}'")
        
        # 4. ìˆ«ì í¬í•¨ í‚¤ì›Œë“œ (ì˜ˆ: 2ì¸ì‹¤, 3ê°œì›” ë“±)
        number_keywords = re.findall(r'\d+[ê°€-í£]{1,3}', item)
        for keyword in number_keywords:
            if keyword not in keywords:
                keywords.append(keyword)
                logger.debug(f"  ìˆ«ì í‚¤ì›Œë“œ: '{keyword}'")
        
        # 5. ìµœì¢… í‚¤ì›Œë“œ ì •ì œ ë° ìˆœì„œ ì¡°ì •
        final_keywords = []
        
        # ìš°ì„ ìˆœìœ„: êµ¬ì²´ì  í‚¤ì›Œë“œ > ì˜ì–´ í‚¤ì›Œë“œ > í•œê¸€ í‚¤ì›Œë“œ > ìˆ«ì í‚¤ì›Œë“œ
        for keyword in keywords:
            if len(final_keywords) >= 4:  # ìµœëŒ€ 4ê°œë¡œ ì œí•œ
                break
            if len(keyword) >= 2 and keyword not in final_keywords:
                final_keywords.append(keyword)
        
        logger.debug(f"  ìµœì¢… í‚¤ì›Œë“œ: {final_keywords}")
        return final_keywords
    
    def _is_meaningful_keyword(self, word: str) -> bool:
        """í‚¤ì›Œë“œê°€ ê²€ìƒ‰ì— ì˜ë¯¸ìˆëŠ”ì§€ íŒë‹¨"""
        # ë„ˆë¬´ ì¼ë°˜ì ì´ê±°ë‚˜ ì¶”ìƒì ì¸ ë‹¨ì–´ë“¤ ì œì™¸
        generic_words = [
            'ê³„íš', 'ì¤€ë¹„', 'í™•ì¸', 'ë°©ë²•', 'ì¶”ì²œ', 'ì •ë³´', 'ì¡°ì‚¬',
            'ì„ íƒ', 'ê²°ì •', 'ê³ ë ¤', 'ê²€í† ', 'ì ê²€', 'ê´€ë¦¬', 'ì§„í–‰',
            'ì™„ë£Œ', 'ë‹¬ì„±', 'ì„±ê³µ', 'ì‹¤íŒ¨', 'ë¬¸ì œ', 'í•´ê²°', 'ê°œì„ ',
            'ì‹œì‘', 'ë§ˆë¬´ë¦¬', 'ì²´í¬', 'ë¦¬ìŠ¤íŠ¸', 'ëª©ë¡', 'í•­ëª©'
        ]
        
        return word not in generic_words and len(word) >= 2
    
    def _generate_item_specific_queries(self, keywords: List[str], context: str = "") -> List[str]:
        """í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¨ì¼ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (1:1 ë§¤í•‘)"""
        if not keywords:
            return []
        
        main_keyword = keywords[0]
        additional_keywords = " ".join(keywords[1:2]) if len(keywords) > 1 else ""
        
        # ê°€ì¥ ì ì ˆí•œ ë‹¨ì¼ ì¿¼ë¦¬ ìƒì„±
        if additional_keywords:
            primary_query = f"{main_keyword} {additional_keywords} ë°©ë²• ì¶”ì²œ"
        else:
            primary_query = f"{main_keyword} ë°©ë²• ì¶”ì²œ"
        
        # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê°œì¸í™” (ë” êµ¬ì²´ì ì¸ ì¿¼ë¦¬ ì„ í˜¸)
        if context and len(context) > 5:
            context_short = context[:30]  # ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ
            contextual_query = f"{main_keyword} {context_short} ì¶”ì²œ"
            return [contextual_query]  # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ì´ë¥¼ ìš°ì„ 
        
        return [primary_query]  # ì•„ì´í…œë‹¹ ì •í™•íˆ 1ê°œ ì¿¼ë¦¬
    
    def _extract_answer_context(self, answers: List[Dict[str, Any]]) -> str:
        """ë‹µë³€ì—ì„œ ê²€ìƒ‰ì— ìœ ìš©í•œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìœ ì—°í•œ ë°©ì‹)"""
        meaningful_answers = []
        
        for answer_item in answers:
            answer = answer_item.get("answer", "")
            
            if isinstance(answer, list):
                answer = " ".join(answer)
            
            # ì˜ë¯¸ìˆëŠ” ë‹µë³€ í•„í„°ë§ (ì¼ë°˜ì ì¸ ì¡°ê±´ë“¤)
            if self._is_meaningful_answer(answer):
                meaningful_answers.append(answer.strip())
        
        # ë‹µë³€ ê¸¸ì´ì™€ êµ¬ì²´ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ê¸´ ë‹µë³€ì´ ë” êµ¬ì²´ì ì¼ ê°€ëŠ¥ì„±)
        meaningful_answers.sort(key=len, reverse=True)
        
        # ìƒìœ„ ë‹µë³€ë“¤ì„ ì¡°í•© (ìµœëŒ€ 3ê°œ)
        selected_answers = meaningful_answers[:3]
        final_context = " ".join(selected_answers)
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ì— ì í•©í•œ ê¸¸ì´ë¡œ ì¡°ì •
        if len(final_context) > 120:
            final_context = final_context[:117] + "..."
        
        return final_context
    
    def _is_meaningful_answer(self, answer: str) -> bool:
        """ë‹µë³€ì´ ì˜ë¯¸ìˆëŠ” ì»¨í…ìŠ¤íŠ¸ì¸ì§€ íŒë‹¨"""
        if not answer or len(answer.strip()) < 2:
            return False
        
        answer = answer.strip()
        
        # ëª…ë°±íˆ ì˜ë¯¸ì—†ëŠ” ë‹µë³€ë“¤ ì œì™¸
        meaningless_patterns = [
            # ë‹¨ì¼ ë¬¸ìë‚˜ ê¸°í˜¸
            r'^[ã„±-ã…ã…-ã…£]$',  # ë‹¨ì¼ í•œê¸€ ììŒ/ëª¨ìŒ
            r'^[!@#$%^&*()_+\-=\[\]{}|;:,.<>?]$',  # ë‹¨ì¼ íŠ¹ìˆ˜ë¬¸ì
            r'^\d+$',  # ìˆ«ìë§Œ
            # ë¬´ì˜ë¯¸í•œ ë°˜ë³µ
            r'^(.)\1{2,}$',  # ê°™ì€ ë¬¸ì 3ë²ˆ ì´ìƒ ë°˜ë³µ
            # ì„ì‹œ/ë¹ˆ ë‹µë³€ íŒ¨í„´
            r'^(ì—†ìŒ|ì—†ë‹¤|ëª¨ë¦„|ì˜ëª¨ë¦„|í•´ë‹¹ì—†ìŒ|íŒ¨ìŠ¤)$',
            r'^(.|_|-|\s)*$',  # íŠ¹ìˆ˜ë¬¸ìë‚˜ ê³µë°±ë§Œ
        ]
        
        import re
        for pattern in meaningless_patterns:
            if re.match(pattern, answer, re.IGNORECASE):
                return False
        
        # ìµœì†Œ ê¸¸ì´ ì²´í¬ (ë„ˆë¬´ ì§§ì€ ë‹µë³€ ì œì™¸)
        if len(answer) < 3:
            return False
        
        # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ì²´í¬
        meaningful_chars = re.findall(r'[ê°€-í£a-zA-Z0-9]', answer)
        if len(meaningful_chars) < 2:
            return False
        
        return True
    
    def _create_gemini_compatible_schema(self) -> Dict[str, Any]:
        """Gemini API í˜¸í™˜ JSON Schema ìƒì„± (SearchResponseë¥¼ ê¸°ë°˜ìœ¼ë¡œ)"""
        # GeminiëŠ” $defsì™€ $refë¥¼ ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì¸ë¼ì¸ ìŠ¤í‚¤ë§ˆë¡œ ë³€í™˜
        return {
            "type": "object",
            "properties": {
                "tips": {
                    "type": "array",
                    "items": {
                        "type": "string"
                    },
                    "description": "ì‹¤ìš©ì ì¸ íŒê³¼ ì¡°ì–¸"
                },
                "contacts": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "name": {
                                "type": "string",
                                "description": "ì—°ë½ì²˜ ì´ë¦„"
                            },
                            "phone": {
                                "type": "string",
                                "description": "ì „í™”ë²ˆí˜¸"
                            },
                            "email": {
                                "type": "string",
                                "description": "ì´ë©”ì¼ ì£¼ì†Œ"
                            }
                        },
                        "required": ["name"]
                    },
                    "description": "ê´€ë ¨ ì—°ë½ì²˜ ì •ë³´"
                },
                "links": {
                    "type": "array",
                    "items": {
                        "type": "object",
                        "properties": {
                            "title": {
                                "type": "string",
                                "description": "ë§í¬ ì œëª©"
                            },
                            "url": {
                                "type": "string",
                                "description": "ì›¹ì‚¬ì´íŠ¸ URL"
                            }
                        },
                        "required": ["title", "url"]
                    },
                    "description": "ìœ ìš©í•œ ì›¹ì‚¬ì´íŠ¸ ë§í¬"
                },
                "price": {
                    "type": "string",
                    "description": "ì˜ˆìƒ ë¹„ìš© ë˜ëŠ” ê°€ê²© ì •ë³´"
                },
                "location": {
                    "type": "string", 
                    "description": "ìœ„ì¹˜ ë˜ëŠ” ì¥ì†Œ ì •ë³´"
                }
            },
            "required": ["tips", "contacts", "links"]
        }

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
gemini_service = GeminiService() 