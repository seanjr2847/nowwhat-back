import asyncio
import aiohttp
import logging
from typing import List, Dict, Optional, Any
from dataclasses import dataclass
from app.core.config import settings

logger = logging.getLogger(__name__)

@dataclass
class SearchResult:
    """Perplexity API ê²€ìƒ‰ ê²°ê³¼"""
    query: str
    content: str
    sources: List[str]
    success: bool
    error_message: Optional[str] = None

class PerplexityService:
    """Perplexity APIë¥¼ í†µí•œ ì‹¤ì‹œê°„ ì •ë³´ ê²€ìƒ‰ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.api_url = "https://api.perplexity.ai/chat/completions"
        self.api_key = getattr(settings, 'PERPLEXITY_API_KEY', '')
        self.max_concurrent_searches = getattr(settings, 'MAX_CONCURRENT_SEARCHES', 5)  # 10 -> 5ë¡œ ì¤„ì„
        self.timeout_seconds = getattr(settings, 'SEARCH_TIMEOUT_SECONDS', 15)
        
        # ìƒì„¸í•œ ì´ˆê¸°í™” ë¡œê¹…
        logger.info("=" * 60)
        logger.info("ğŸ” PERPLEXITY SERVICE ì´ˆê¸°í™”")
        logger.info("=" * 60)
        
        # API í‚¤ ìƒíƒœ ë¡œê¹…
        if not self.api_key:
            logger.error("ğŸš¨ PERPLEXITY_API_KEY not found in environment variables!")
            logger.error("   âŒ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œì— detailsê°€ ì¶”ê°€ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            logger.error("   ğŸ’¡ í™˜ê²½ë³€ìˆ˜ PERPLEXITY_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            logger.error("   ğŸ“ ì˜ˆì‹œ: export PERPLEXITY_API_KEY=pplx-xxxxx")
        else:
            logger.info(f"âœ… Perplexity API í‚¤ í™•ì¸ë¨")
            logger.info(f"   ğŸ”‘ í‚¤ ê¸¸ì´: {len(self.api_key)} ë¬¸ì")
            logger.info(f"   ğŸŒ API URL: {self.api_url}")
            logger.info(f"   âš¡ ìµœëŒ€ ë™ì‹œ ê²€ìƒ‰: {self.max_concurrent_searches}ê°œ")
            logger.info(f"   â±ï¸  ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ: {self.timeout_seconds}ì´ˆ")
        
        logger.info("=" * 60)
    
    async def parallel_search(self, queries: List[str]) -> List[SearchResult]:
        """10ê°œì˜ ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ë³‘ë ¬ë¡œ ì‹¤í–‰"""
        logger.info("ğŸš€ PERPLEXITY ë³‘ë ¬ ê²€ìƒ‰ ì‹œì‘")
        logger.info(f"   ğŸ“ ìš”ì²­ëœ ì¿¼ë¦¬ ìˆ˜: {len(queries)}ê°œ")
        
        if not queries:
            logger.warning("âš ï¸  ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
            return []
        
        # ì¿¼ë¦¬ ë‚´ìš© ë¡œê¹…
        for i, query in enumerate(queries[:5]):  # ì²˜ìŒ 5ê°œë§Œ ë¡œê¹…
            logger.info(f"   ğŸ” ì¿¼ë¦¬ {i+1}: {query}")
        if len(queries) > 5:
            logger.info(f"   ... ê·¸ ì™¸ {len(queries) - 5}ê°œ ë”")
        
        if not self.api_key:
            logger.error("ğŸš¨ PERPLEXITY API í‚¤ê°€ ì—†ì–´ ê²€ìƒ‰ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            logger.error("   âŒ ëª¨ë“  ê²€ìƒ‰ì´ ì‹¤íŒ¨ ì²˜ë¦¬ë©ë‹ˆë‹¤")
            return [self._create_empty_result(query) for query in queries]
        
        # ìµœëŒ€ ë™ì‹œ ê²€ìƒ‰ ìˆ˜ ì œí•œ
        limited_queries = queries[:self.max_concurrent_searches]
        if len(queries) > self.max_concurrent_searches:
            logger.warning(f"âš ï¸  ì¿¼ë¦¬ ìˆ˜ ì œí•œ: {len(queries)} â†’ {len(limited_queries)}ê°œ")
        
        try:
            logger.info(f"âš¡ {len(limited_queries)}ê°œ ì¿¼ë¦¬ ë³‘ë ¬ ì‹¤í–‰ ì¤‘...")
            
            # ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
            tasks = [self._search_single_query(query) for query in limited_queries]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ì˜ˆì™¸ ì²˜ë¦¬ ë° ê²°ê³¼ ì •ë¦¬
            processed_results = []
            success_queries = []
            failed_queries = []
            
            for i, result in enumerate(results):
                query = limited_queries[i]
                if isinstance(result, Exception):
                    logger.error(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨ [{i+1}]: '{query[:50]}...' - {str(result)}")
                    processed_results.append(self._create_error_result(query, str(result)))
                    failed_queries.append(query)
                else:
                    if result.success:
                        logger.info(f"âœ… ê²€ìƒ‰ ì„±ê³µ [{i+1}]: '{query[:50]}...' ({len(result.content)}ì)")
                        success_queries.append(query)
                    else:
                        logger.warning(f"âš ï¸  ê²€ìƒ‰ ì‹¤íŒ¨ [{i+1}]: '{query[:50]}...' - {result.error_message}")
                        failed_queries.append(query)
                    processed_results.append(result)
            
            success_count = len(success_queries)
            failed_count = len(failed_queries)
            
            # ê²°ê³¼ ìš”ì•½
            logger.info("=" * 60)
            logger.info("ğŸ“Š PERPLEXITY ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½")
            logger.info("=" * 60)
            logger.info(f"âœ… ì„±ê³µ: {success_count}ê°œ")
            logger.info(f"âŒ ì‹¤íŒ¨: {failed_count}ê°œ")
            logger.info(f"ğŸ“ˆ ì„±ê³µë¥ : {(success_count/len(limited_queries)*100):.1f}%")
            
            if success_count > 0:
                # ì„±ê³µí•œ ê²€ìƒ‰ ê²°ê³¼ì˜ ë‚´ìš© ê¸¸ì´ í†µê³„
                content_lengths = [len(r.content) for r in processed_results if r.success and r.content]
                if content_lengths:
                    avg_length = sum(content_lengths) / len(content_lengths)
                    min_length = min(content_lengths)
                    max_length = max(content_lengths)
                    logger.info(f"ğŸ“ ì‘ë‹µ ê¸¸ì´: í‰ê·  {avg_length:.0f}ì (ìµœì†Œ {min_length}, ìµœëŒ€ {max_length})")
                
                # ì„±ê³µí•œ ì¿¼ë¦¬ ëª‡ ê°œ ì˜ˆì‹œ
                for query in success_queries[:3]:
                    logger.info(f"   âœ… '{query[:40]}...'")
            
            if failed_count > 0:
                logger.warning(f"âš ï¸  ì‹¤íŒ¨í•œ ì¿¼ë¦¬ {min(3, failed_count)}ê°œ ì˜ˆì‹œ:")
                for query in failed_queries[:3]:
                    logger.warning(f"   âŒ '{query[:40]}...'")
            
            logger.info("=" * 60)
            
            return processed_results
            
        except Exception as e:
            logger.error(f"ğŸ’¥ ë³‘ë ¬ ê²€ìƒ‰ ì „ì²´ ì‹¤íŒ¨: {str(e)}")
            logger.error(f"   ğŸ”„ ëª¨ë“  ì¿¼ë¦¬ë¥¼ ì‹¤íŒ¨ ì²˜ë¦¬í•©ë‹ˆë‹¤")
            return [self._create_error_result(query, str(e)) for query in limited_queries]
    
    async def _search_single_query(self, query: str) -> SearchResult:
        """ë‹¨ì¼ ê²€ìƒ‰ ì¿¼ë¦¬ ì‹¤í–‰"""
        start_time = asyncio.get_event_loop().time()
        logger.debug(f"ğŸ” ë‹¨ì¼ ê²€ìƒ‰ ì‹œì‘: '{query[:50]}...'")
        
        try:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "sonar",
                "messages": [
                    {
                        "role": "system",
                        "content": """You are a helpful assistant that provides structured information. 
                        Always respond in JSON format with the following structure:
                        {
                            "tips": ["practical tip 1", "practical tip 2"],
                            "contacts": [{"name": "contact name", "phone": "phone number", "email": "email"}],
                            "links": [{"title": "link description", "url": "https://..."}],
                            "price": "price information or null",
                            "location": "location/address information or null"
                        }
                        Include only relevant, accurate information. Use null for missing data."""
                    },
                    {
                        "role": "user", 
                        "content": f"{query} (í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”.)"
                    }
                ],
                "max_tokens": 1000,  # 500 -> 1000ìœ¼ë¡œ ëŠ˜ë¦¼
                "temperature": 0.1,  # ë” ì¼ê´€ì„± ìˆê²Œ
                "stream": False
            }
            
            timeout = aiohttp.ClientTimeout(total=self.timeout_seconds)
            
            async with aiohttp.ClientSession(timeout=timeout) as session:
                logger.debug(f"ğŸ“¡ API ìš”ì²­ ì „ì†¡ ì¤‘: {self.api_url}")
                async with session.post(self.api_url, json=payload, headers=headers) as response:
                    elapsed = asyncio.get_event_loop().time() - start_time
                    
                    if response.status == 200:
                        logger.debug(f"âœ… API ì‘ë‹µ ìˆ˜ì‹  ({elapsed:.2f}ì´ˆ): '{query[:30]}...'")
                        data = await response.json()
                        result = self._parse_perplexity_response(query, data)
                        
                        if result.success:
                            logger.debug(f"âœ… íŒŒì‹± ì„±ê³µ: {len(result.content)}ì ì‘ë‹µ")
                        else:
                            logger.warning(f"âš ï¸  íŒŒì‹± ì‹¤íŒ¨: {result.error_message}")
                        
                        return result
                    else:
                        error_text = await response.text()
                        logger.error(f"ğŸš¨ Perplexity API ì˜¤ë¥˜ {response.status}")
                        logger.error(f"   ì¿¼ë¦¬: '{query[:50]}...'")
                        logger.error(f"   ì‘ë‹µ: {error_text[:200]}...")
                        logger.error(f"   ì†Œìš”ì‹œê°„: {elapsed:.2f}ì´ˆ")
                        
                        return self._create_error_result(query, f"API error {response.status}: {error_text[:100]}")
                        
        except asyncio.TimeoutError:
            elapsed = asyncio.get_event_loop().time() - start_time
            logger.error(f"â° ê²€ìƒ‰ íƒ€ì„ì•„ì›ƒ ({elapsed:.2f}ì´ˆ)")
            logger.error(f"   ì¿¼ë¦¬: '{query[:50]}...'")
            logger.error(f"   íƒ€ì„ì•„ì›ƒ ì„¤ì •: {self.timeout_seconds}ì´ˆ")
            return self._create_error_result(query, f"Search timeout after {elapsed:.2f}s")
        except Exception as e:
            elapsed = asyncio.get_event_loop().time() - start_time
            logger.error(f"ğŸ’¥ ê²€ìƒ‰ ì˜ˆì™¸ ë°œìƒ ({elapsed:.2f}ì´ˆ)")
            logger.error(f"   ì¿¼ë¦¬: '{query[:50]}...'")
            logger.error(f"   ì˜¤ë¥˜: {str(e)}")
            return self._create_error_result(query, f"Exception: {str(e)}")
    
    def _parse_perplexity_response(self, query: str, data: Dict[str, Any]) -> SearchResult:
        """Perplexity API ì‘ë‹µ íŒŒì‹± (JSON êµ¬ì¡°í™”ëœ ì‘ë‹µ)"""
        try:
            if "choices" not in data or not data["choices"]:
                return self._create_error_result(query, "No choices in response")
            
            choice = data["choices"][0]
            if "message" not in choice:
                return self._create_error_result(query, "No message in choice")
            
            content = choice["message"].get("content", "").strip()
            if not content:
                return self._create_error_result(query, "Empty content in response")
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                import json
                # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ (```json ... ``` í˜•íƒœë¡œ ì˜¬ ìˆ˜ ìˆìŒ)
                json_content = content
                if "```json" in content:
                    start = content.find("```json") + 7
                    end = content.find("```", start)
                    if end != -1:
                        json_content = content[start:end].strip()
                elif "{" in content:
                    # ì²« ë²ˆì§¸ { ë¶€í„° ë§ˆì§€ë§‰ } ê¹Œì§€ ì¶”ì¶œ
                    start = content.find("{")
                    end = content.rfind("}") + 1
                    if start != -1 and end > start:
                        json_content = content[start:end]
                
                # ì˜ë¦° JSON ë³µêµ¬ ì‹œë„
                if json_content.count('"') % 2 != 0:
                    # í™€ìˆ˜ê°œì˜ ë”°ì˜´í‘œê°€ ìˆìœ¼ë©´ ë¬¸ìì—´ì´ ì˜ë¦¼
                    json_content += '"'
                
                # ì—´ë¦° ë°°ì—´/ê°ì²´ ë‹«ê¸°
                open_brackets = json_content.count('[') - json_content.count(']')
                open_braces = json_content.count('{') - json_content.count('}')
                
                if open_brackets > 0:
                    json_content += ']' * open_brackets
                if open_braces > 0:
                    json_content += '}' * open_braces
                
                structured_data = json.loads(json_content)
                logger.info(f"Successfully parsed JSON response for query: {query[:50]}...")
                
                return SearchResult(
                    query=query,
                    content=json.dumps(structured_data),  # êµ¬ì¡°í™”ëœ ë°ì´í„°ë¥¼ JSON ë¬¸ìì—´ë¡œ
                    sources=structured_data.get("links", []),
                    success=True
                )
                
            except json.JSONDecodeError as json_err:
                logger.warning(f"Failed to parse JSON for query '{query}': {json_err}")
                logger.warning(f"Raw content: {content[:200]}...")
                # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ê¸°ì¡´ í…ìŠ¤íŠ¸ ë°©ì‹ìœ¼ë¡œ í´ë°±
                sources = self._extract_sources_from_content(content)
                return SearchResult(
                    query=query,
                    content=content,
                    sources=sources,
                    success=True
                )
            
        except Exception as e:
            logger.error(f"Failed to parse Perplexity response for query '{query}': {str(e)}")
            return self._create_error_result(query, f"Parse error: {str(e)}")
    
    def _extract_sources_from_content(self, content: str) -> List[str]:
        """ì½˜í…ì¸ ì—ì„œ ì†ŒìŠ¤ URL ì¶”ì¶œ"""
        import re
        
        # URL íŒ¨í„´ ë§¤ì¹­
        url_pattern = r'https?://[^\s\])]+'
        sources = re.findall(url_pattern, content)
        
        # ì¤‘ë³µ ì œê±° ë° ì •ë¦¬
        unique_sources = list(set(sources))
        return unique_sources[:5]  # ìµœëŒ€ 5ê°œ ì†ŒìŠ¤
    
    def _create_empty_result(self, query: str) -> SearchResult:
        """ë¹ˆ ê²°ê³¼ ìƒì„± (API í‚¤ ì—†ìŒ)"""
        return SearchResult(
            query=query,
            content="ê²€ìƒ‰ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            sources=[],
            success=False,
            error_message="Perplexity API key not configured"
        )
    
    def _create_error_result(self, query: str, error_message: str) -> SearchResult:
        """ì—ëŸ¬ ê²°ê³¼ ìƒì„±"""
        return SearchResult(
            query=query,
            content="",
            sources=[],
            success=False,
            error_message=error_message
        )
    
    def generate_search_queries_from_checklist(
        self,
        checklist_items: List[str],
        goal: str,
        answers: List[Dict[str, Any]]
    ) -> List[str]:
        """ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ë²”ìš©ì  ë°©ì‹)"""
        
        logger.info("ğŸ¯ PERPLEXITY ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± ì‹œì‘")
        logger.info(f"   ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œ: {len(checklist_items)}ê°œ")
        logger.info(f"   ğŸ¯ ëª©í‘œ: {goal[:50]}...")
        logger.info(f"   ğŸ’¬ ë‹µë³€: {len(answers)}ê°œ")
        
        # ë‹µë³€ì—ì„œ í•µì‹¬ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ
        answer_context = self._extract_answer_context(answers)
        logger.info(f"   ğŸ” ì¶”ì¶œëœ ì»¨í…ìŠ¤íŠ¸: '{answer_context[:80]}...' ({len(answer_context)}ì)")
        
        search_queries = []
        
        # ê° ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œì„ ê¸°ë°˜ìœ¼ë¡œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
        processed_items = checklist_items[:10]  # ìµœëŒ€ 10ê°œ ì•„ì´í…œ
        logger.info(f"   ğŸ“ ì²˜ë¦¬í•  ì•„ì´í…œ: {len(processed_items)}ê°œ")
        
        for i, item in enumerate(processed_items):
            logger.debug(f"   ğŸ” ì•„ì´í…œ {i+1} ì²˜ë¦¬: '{item[:50]}...'")
            
            # ì•„ì´í…œì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ
            core_keywords = self._extract_core_keywords_from_item(item)
            logger.debug(f"      í‚¤ì›Œë“œ: {core_keywords}")
            
            if core_keywords:
                # ì—¬ëŸ¬ íŒ¨í„´ì˜ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
                queries = self._generate_item_specific_queries(core_keywords, answer_context)
                logger.debug(f"      ìƒì„±ëœ ì¿¼ë¦¬: {queries}")
                search_queries.extend(queries)
            else:
                logger.warning(f"      âš ï¸  í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: '{item[:30]}...'")
        
        # ì¤‘ë³µ ì œê±° ë° ê¸¸ì´ ì œí•œ
        unique_queries = list(dict.fromkeys(search_queries))[:15]  # ìµœëŒ€ 15ê°œ
        
        logger.info("=" * 50)
        logger.info("ğŸ“ ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ ëª©ë¡")
        logger.info("=" * 50)
        for i, query in enumerate(unique_queries):
            logger.info(f"   {i+1:2d}. {query}")
        logger.info("=" * 50)
        
        logger.info(f"âœ… ì¿¼ë¦¬ ìƒì„± ì™„ë£Œ: {len(search_queries)} â†’ {len(unique_queries)}ê°œ (ì¤‘ë³µ ì œê±°)")
        
        if not unique_queries:
            logger.error("ğŸš¨ ìƒì„±ëœ ê²€ìƒ‰ ì¿¼ë¦¬ê°€ ì—†ìŠµë‹ˆë‹¤!")
            logger.error("   ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œì´ ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        
        return unique_queries
    
    def _extract_core_keywords_from_item(self, item: str) -> List[str]:
        """ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œì—ì„œ ê²€ìƒ‰ì— ìœ ìš©í•œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        import re
        
        # ë¶ˆìš©ì–´ ì œê±°
        stopwords = [
            'ì„', 'ë¥¼', 'ì´', 'ê°€', 'ì€', 'ëŠ”', 'ì˜', 'ì—', 'ì—ì„œ', 'ì™€', 'ê³¼',
            'í•˜ê¸°', 'í•˜ì„¸ìš”', 'í•©ë‹ˆë‹¤', 'ìœ„í•œ', 'ìœ„í•´', 'í†µí•´', 'ëŒ€í•œ', 'í•¨ê»˜'
        ]
        
        # ëª…ì‚¬í˜• í‚¤ì›Œë“œ ìš°ì„  ì¶”ì¶œ
        noun_patterns = [
            r'[ê°€-í£]{2,}(?:ì•±|ì–´í”Œ|í”Œë«í¼|ì„œë¹„ìŠ¤|ì‚¬ì´íŠ¸)',  # ì„œë¹„ìŠ¤ ê´€ë ¨
            r'[ê°€-í£]{2,}(?:êµì¬|ì±…|ìë£Œ|ê°€ì´ë“œ)',  # í•™ìŠµ ìë£Œ
            r'[ê°€-í£]{2,}(?:ê³„íš|ì¼ì •|ìŠ¤ì¼€ì¤„)',  # ê³„íš ê´€ë ¨
            r'[ê°€-í£]{2,}(?:ì˜ˆì‚°|ë¹„ìš©|ê°€ê²©|ëˆ)',  # ë¹„ìš© ê´€ë ¨
            r'[ê°€-í£]{2,}(?:ë°©ë²•|ë°©ì‹|íŒ|ë…¸í•˜ìš°)',  # ë°©ë²• ê´€ë ¨
        ]
        
        keywords = []
        
        # íŠ¹ìˆ˜ íŒ¨í„´ ë¨¼ì € ì¶”ì¶œ
        for pattern in noun_patterns:
            matches = re.findall(pattern, item)
            keywords.extend(matches)
        
        # ì¼ë°˜ ëª…ì‚¬ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
        words = re.findall(r'[ê°€-í£a-zA-Z]{2,}', item)
        for word in words:
            if word not in stopwords and word not in keywords:
                keywords.append(word)
        
        return keywords[:5]  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
    
    def _generate_item_specific_queries(self, keywords: List[str], context: str = "") -> List[str]:
        """í‚¤ì›Œë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±"""
        if not keywords:
            return []
        
        main_keyword = keywords[0]
        additional_keywords = " ".join(keywords[1:3]) if len(keywords) > 1 else ""
        
        # ê²€ìƒ‰ íŒ¨í„´ í…œí”Œë¦¿ (ë²”ìš©ì )
        query_patterns = [
            f"{main_keyword} ë°©ë²• ì¶”ì²œ",
            f"{main_keyword} ê°€ì´ë“œ íŒ", 
            f"{main_keyword} {additional_keywords} ì •ë³´".strip(),
        ]
        
        # ì»¨í…ìŠ¤íŠ¸ê°€ ìˆìœ¼ë©´ ê°œì¸í™”
        if context and len(context) > 5:
            context_short = context[:30]  # ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ
            query_patterns.append(f"{main_keyword} {context_short} ì¶”ì²œ")
        
        return query_patterns[:2]  # ì•„ì´í…œë‹¹ ìµœëŒ€ 2ê°œ ì¿¼ë¦¬
    
    def _extract_answer_context(self, answers: List[Dict[str, Any]]) -> str:
        """ë‹µë³€ì—ì„œ ê²€ìƒ‰ì— ìœ ìš©í•œ ì»¨í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìœ ì—°í•œ ë°©ì‹)"""
        meaningful_answers = []
        
        for answer_item in answers:
            answer = answer_item.get("answer", "")
            
            if isinstance(answer, list):
                answer = " ".join(answer)
            
            # ì˜ë¯¸ìˆëŠ” ë‹µë³€ í•„í„°ë§ (ì¼ë°˜ì ì¸ ì¡°ê±´ë“¤)
            if self._is_meaningful_answer(answer):
                meaningful_answers.append(answer.strip())
        
        # ë‹µë³€ ê¸¸ì´ì™€ êµ¬ì²´ì„±ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ê¸´ ë‹µë³€ì´ ë” êµ¬ì²´ì ì¼ ê°€ëŠ¥ì„±)
        meaningful_answers.sort(key=len, reverse=True)
        
        # ìƒìœ„ ë‹µë³€ë“¤ì„ ì¡°í•© (ìµœëŒ€ 3ê°œ)
        selected_answers = meaningful_answers[:3]
        final_context = " ".join(selected_answers)
        
        # ê²€ìƒ‰ ì¿¼ë¦¬ì— ì í•©í•œ ê¸¸ì´ë¡œ ì¡°ì •
        if len(final_context) > 120:
            final_context = final_context[:117] + "..."
        
        return final_context
    
    def _is_meaningful_answer(self, answer: str) -> bool:
        """ë‹µë³€ì´ ì˜ë¯¸ìˆëŠ” ì»¨í…ìŠ¤íŠ¸ì¸ì§€ íŒë‹¨"""
        if not answer or len(answer.strip()) < 2:
            return False
        
        answer = answer.strip()
        
        # ëª…ë°±íˆ ì˜ë¯¸ì—†ëŠ” ë‹µë³€ë“¤ ì œì™¸
        meaningless_patterns = [
            # ë‹¨ì¼ ë¬¸ìë‚˜ ê¸°í˜¸
            r'^[ã„±-ã…ã…-ã…£]$',  # ë‹¨ì¼ í•œê¸€ ììŒ/ëª¨ìŒ
            r'^[!@#$%^&*()_+\-=\[\]{}|;:,.<>?]$',  # ë‹¨ì¼ íŠ¹ìˆ˜ë¬¸ì
            r'^\d+$',  # ìˆ«ìë§Œ
            # ë¬´ì˜ë¯¸í•œ ë°˜ë³µ
            r'^(.)\1{2,}$',  # ê°™ì€ ë¬¸ì 3ë²ˆ ì´ìƒ ë°˜ë³µ
            # ì„ì‹œ/ë¹ˆ ë‹µë³€ íŒ¨í„´
            r'^(ì—†ìŒ|ì—†ë‹¤|ëª¨ë¦„|ì˜ëª¨ë¦„|í•´ë‹¹ì—†ìŒ|íŒ¨ìŠ¤)$',
            r'^(.|_|-|\s)*$',  # íŠ¹ìˆ˜ë¬¸ìë‚˜ ê³µë°±ë§Œ
        ]
        
        import re
        for pattern in meaningless_patterns:
            if re.match(pattern, answer, re.IGNORECASE):
                return False
        
        # ìµœì†Œ ê¸¸ì´ ì²´í¬ (ë„ˆë¬´ ì§§ì€ ë‹µë³€ ì œì™¸)
        if len(answer) < 3:
            return False
        
        # ì˜ë¯¸ìˆëŠ” ë‹¨ì–´ê°€ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ì²´í¬
        meaningful_chars = re.findall(r'[ê°€-í£a-zA-Z0-9]', answer)
        if len(meaningful_chars) < 2:
            return False
        
        return True
    
    async def enhance_checklist_with_search(
        self, 
        base_checklist: List[str], 
        search_results: List[SearchResult]
    ) -> List[str]:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í™œìš©í•˜ì—¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ ë³´ê°•"""
        
        if not search_results:
            return base_checklist
        
        # ì„±ê³µì ì¸ ê²€ìƒ‰ ê²°ê³¼ë§Œ í•„í„°ë§
        successful_results = [r for r in search_results if r.success and r.content]
        
        if not successful_results:
            logger.warning("No successful search results to enhance checklist")
            return base_checklist
        
        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ìœ ìš©í•œ ì •ë³´ ì¶”ì¶œ
        enhancement_info = []
        for result in successful_results:
            # ì§§ê³  ì‹¤ìš©ì ì¸ íŒ ì¶”ì¶œ
            tips = self._extract_actionable_tips(result.content)
            enhancement_info.extend(tips)
        
        # ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ í•„í„°ë§
        unique_enhancements = list(set(enhancement_info))
        quality_enhancements = [tip for tip in unique_enhancements if len(tip) > 10 and len(tip) < 100]
        
        # ê¸°ì¡´ ì²´í¬ë¦¬ìŠ¤íŠ¸ì™€ ë³‘í•©
        enhanced_checklist = base_checklist.copy()
        
        # ìœ ìš©í•œ ì •ë³´ê°€ ìˆìœ¼ë©´ ì²´í¬ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
        for enhancement in quality_enhancements[:5]:  # ìµœëŒ€ 5ê°œ ì¶”ê°€
            if not any(enhancement.lower() in item.lower() for item in enhanced_checklist):
                enhanced_checklist.append(f"ğŸ’¡ {enhancement}")
        
        logger.info(f"Enhanced checklist: {len(base_checklist)} -> {len(enhanced_checklist)} items")
        return enhanced_checklist
    
    def _extract_actionable_tips(self, content: str) -> List[str]:
        """ì½˜í…ì¸ ì—ì„œ ì‹¤í–‰ ê°€ëŠ¥í•œ íŒ ì¶”ì¶œ"""
        tips = []
        
        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
        sentences = content.split('. ')
        
        for sentence in sentences:
            sentence = sentence.strip()
            
            # ì‹¤í–‰ ê°€ëŠ¥í•œ íŒì˜ íŠ¹ì§•ì„ ê°€ì§„ ë¬¸ì¥ ì°¾ê¸°
            actionable_keywords = ['ì¶”ì²œ', 'í•„ìš”', 'ì¤€ë¹„', 'í™•ì¸', 'ì˜ˆì•½', 'êµ¬ë§¤', 'ì‹ ì²­', 'ë°©ë¬¸', 'ì—°ë½']
            
            if any(keyword in sentence for keyword in actionable_keywords):
                if 20 <= len(sentence) <= 80:  # ì ì ˆí•œ ê¸¸ì´
                    tips.append(sentence)
        
        return tips[:3]  # ìµœëŒ€ 3ê°œ íŒ

# ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
perplexity_service = PerplexityService()