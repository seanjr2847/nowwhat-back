from fastapi import APIRouter, HTTPException, Depends, Request
from fastapi.responses import StreamingResponse, Response
from sqlalchemy.orm import Session
import json
import asyncio
import os
import uuid
from app.schemas.questions import (
    QuestionGenerateRequest, QuestionGenerateResponse, 
    Question, Option,
    QuestionAnswersRequest, QuestionAnswersResponse
)
from app.core.auth import get_current_user
from app.core.database import get_db
from app.services.gemini_service import gemini_service
# Removed geo utils for performance optimization
from app.crud.session import (
    validate_session_basic,
    save_question_set
)
from app.services.checklist_orchestrator import checklist_orchestrator, ChecklistGenerationError
from app.models.database import User
from app.core.config import settings
import logging
from typing import Dict, Any

logger = logging.getLogger(__name__)

router = APIRouter()


def get_cors_headers(request: Request = None) -> dict:
    """ë™ì  CORS í—¤ë” ìƒì„±"""
    # ìš”ì²­ì˜ Origin í—¤ë” í™•ì¸
    origin = None
    if request:
        origin = request.headers.get("origin")
        logger.debug(f"Request origin: {origin}")
    
    # í—ˆìš©ëœ Origin í™•ì¸ ë° ê²°ì •
    allowed_origin = None
    
    if origin:
        # ì •í™•í•œ ë§¤ì¹˜ í™•ì¸
        if origin in settings.ALLOWED_ORIGINS:
            allowed_origin = origin
        # Vercel ë„ë©”ì¸ íŒ¨í„´ í™•ì¸
        elif origin.endswith(".vercel.app") and ("nowwhat-front" in origin):
            allowed_origin = origin
            logger.info(f"Allowing Vercel domain: {origin}")
        # ê°œë°œ í™˜ê²½ì—ì„œëŠ” localhost íŒ¨í„´ í—ˆìš©
        elif settings.ENV == "development" and ("localhost" in origin or "127.0.0.1" in origin):
            allowed_origin = origin
    
    # ê¸°ë³¸ê°’ ì„¤ì •
    if not allowed_origin:
        allowed_origin = settings.ALLOWED_ORIGINS[0] if settings.ALLOWED_ORIGINS else "https://nowwhat-front.vercel.app"
    
    headers = {
        "Access-Control-Allow-Origin": allowed_origin,
        "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
        "Access-Control-Allow-Headers": "Content-Type, Authorization, Accept, X-Requested-With",
        "Access-Control-Allow-Credentials": "true",
        "Access-Control-Max-Age": "86400",  # 24ì‹œê°„
        "Access-Control-Expose-Headers": "*"
    }
    
    logger.debug(f"CORS headers: {headers}")
    return headers


# JSON ì™„ì „ì„± ê²€ì¦ í•¨ìˆ˜
async def verify_json_completeness(content: str, stream_id: str) -> bool:
    """ìŠ¤íŠ¸ë¦¬ë°ëœ JSON ë°ì´í„°ì˜ ì™„ì „ì„± ê²€ì¦"""
    try:
        if not content or len(content.strip()) < 50:
            logger.warning(f"ğŸš¨ Content too short [{stream_id}]: {len(content)} chars")
            return False
        
        # ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
        clean_content = content.strip()
        if '```json' in clean_content:
            start = clean_content.find('```json') + 7
            end = clean_content.rfind('```')
            if end > start:
                clean_content = clean_content[start:end].strip()
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            parsed = json.loads(clean_content)
        except json.JSONDecodeError as e:
            logger.warning(f"ğŸš¨ JSON parsing failed [{stream_id}]: {str(e)}")
            return False
        
        # ê¸°ë³¸ êµ¬ì¡° ê²€ì¦
        if not isinstance(parsed, dict) or 'questions' not in parsed:
            logger.warning(f"ğŸš¨ Invalid structure [{stream_id}]: missing 'questions' field")
            return False
        
        questions = parsed['questions']
        if not isinstance(questions, list) or len(questions) == 0:
            logger.warning(f"ğŸš¨ Invalid questions [{stream_id}]: not a list or empty")
            return False
        
        # ê° ì§ˆë¬¸ì˜ í•„ìˆ˜ í•„ë“œ ê²€ì¦
        for i, question in enumerate(questions):
            if not isinstance(question, dict):
                logger.warning(f"ğŸš¨ Question {i} invalid [{stream_id}]: not a dict")
                return False
            
            required_fields = ['id', 'text', 'type', 'options']
            for field in required_fields:
                if field not in question:
                    logger.warning(f"ğŸš¨ Question {i} missing '{field}' [{stream_id}]")
                    return False
            
            # ì˜µì…˜ ê²€ì¦
            if question['type'] == 'multiple':
                options = question['options']
                if not isinstance(options, list) or len(options) == 0:
                    logger.warning(f"ğŸš¨ Question {i} invalid options [{stream_id}]")
                    return False
                
                # ê° ì˜µì…˜ì´ ì™„ì „í•œì§€ ê²€ì¦
                for j, option in enumerate(options):
                    if isinstance(option, dict):
                        if 'text' not in option or not option['text']:
                            logger.warning(f"ğŸš¨ Question {i}, Option {j} incomplete text [{stream_id}]")
                            return False
                        
                        # í…ìŠ¤íŠ¸ê°€ ì¤‘ê°„ì— ì˜ë ¸ëŠ”ì§€ ê²€ì¦ (ê´„í˜¸ë‚˜ ë”°ì˜´í‘œê°€ ì—´ë ¤ìˆëŠ”ì§€)
                        text = option['text']
                        if text.count('(') != text.count(')') or text.count('"') % 2 != 0:
                            logger.warning(f"ğŸš¨ Question {i}, Option {j} truncated text [{stream_id}]: '{text}'")
                            return False
        
        logger.info(f"âœ… JSON validation passed [{stream_id}]: {len(questions)} questions verified")
        return True
        
    except Exception as e:
        logger.error(f"ğŸš¨ JSON validation error [{stream_id}]: {str(e)}")
        return False


# í–¥ìƒëœ JSON ê²€ì¦ ë° ìë™ ìˆ˜ì • í•¨ìˆ˜
async def verify_and_fix_json_completeness(content: str, stream_id: str) -> tuple[bool, list]:
    """JSON ì™„ì „ì„± ê²€ì¦í•˜ê³  ë¶ˆì™„ì „í•œ ê²½ìš° ìµœëŒ€í•œ ë³µêµ¬ ì‹œë„"""
    try:
        if not content or len(content.strip()) < 50:
            logger.warning(f"ğŸš¨ Content too short [{stream_id}]: {len(content)} chars")
            return False, []
        
        # ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
        clean_content = content.strip()
        if '```json' in clean_content:
            start = clean_content.find('```json') + 7
            end = clean_content.rfind('```')
            if end > start:
                clean_content = clean_content[start:end].strip()
            else:
                # ë§ˆí¬ë‹¤ìš´ ë¸”ë¡ì´ ë‹«íˆì§€ ì•Šì€ ê²½ìš° - ë§ˆì§€ë§‰ ``` ì—†ì´ ì²˜ë¦¬
                clean_content = clean_content[clean_content.find('```json') + 7:].strip()
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            parsed = json.loads(clean_content)
            questions = parsed.get('questions', [])
            
            # ì™„ì „í•œ êµ¬ì¡°ì¸ì§€ ê²€ì¦
            valid_questions = []
            for i, question in enumerate(questions):
                if isinstance(question, dict) and all(field in question for field in ['id', 'text', 'type', 'options']):
                    # ì˜µì…˜ ê²€ì¦ ë° ìˆ˜ì •
                    if question['type'] == 'multiple' and isinstance(question['options'], list):
                        fixed_options = []
                        for option in question['options']:
                            if isinstance(option, dict) and 'text' in option and option['text']:
                                # ë¶ˆì™„ì „í•œ í…ìŠ¤íŠ¸ ê°ì§€ ë° ìˆ˜ì •
                                text = option['text']
                                if text.count('(') != text.count(')'):
                                    # ì—´ë¦° ê´„í˜¸ê°€ ìˆìœ¼ë©´ ë‹«ì•„ì¤Œ
                                    text += ')' * (text.count('(') - text.count(')'))
                                    option['text'] = text
                                    logger.info(f"ğŸ”§ Auto-fixed unbalanced parentheses in question {i} [{stream_id}]")
                                
                                # idì™€ value í•„ë“œê°€ ì—†ìœ¼ë©´ ìƒì„±
                                if 'id' not in option:
                                    option['id'] = f"opt_{len(fixed_options) + 1}"
                                if 'value' not in option:
                                    option['value'] = option['id']
                                
                                fixed_options.append(option)
                        
                        question['options'] = fixed_options
                        if len(fixed_options) > 0:  # ìµœì†Œ í•˜ë‚˜ì˜ ìœ íš¨í•œ ì˜µì…˜ì´ ìˆëŠ” ê²½ìš°ë§Œ í¬í•¨
                            valid_questions.append(question)
            
            if len(valid_questions) > 0:
                logger.info(f"âœ… JSON validated with fixes [{stream_id}]: {len(valid_questions)} valid questions")
                return True, valid_questions
            
        except json.JSONDecodeError as e:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ë¶€ë¶„ì  ë³µêµ¬ ì‹œë„
            logger.info(f"ğŸ”§ Attempting partial JSON recovery [{stream_id}]: {str(e)}")
            recovered_questions = attempt_partial_json_recovery(clean_content, stream_id)
            if recovered_questions:
                return True, recovered_questions
        
        logger.warning(f"ğŸš¨ Could not validate or fix JSON [{stream_id}]")
        return False, []
        
    except Exception as e:
        logger.error(f"ğŸš¨ JSON validation/fix error [{stream_id}]: {str(e)}")
        return False, []


def attempt_partial_json_recovery(content: str, stream_id: str) -> list:
    """ë¶€ë¶„ì ìœ¼ë¡œ ì†ìƒëœ JSONì—ì„œ ìµœëŒ€í•œ ì§ˆë¬¸ ë°ì´í„° ë³µêµ¬"""
    try:
        # ì™„ì „í•˜ì§€ ì•Šì€ JSONì—ì„œ ì§ˆë¬¸ ê°ì²´ë“¤ ì¶”ì¶œ ì‹œë„
        questions = []
        
        # "questions": [ ì´í›„ ë¶€ë¶„ ì°¾ê¸°
        start_marker = '"questions"'
        if start_marker in content:
            questions_start = content.find(start_marker)
            bracket_start = content.find('[', questions_start)
            if bracket_start != -1:
                # ê° ì§ˆë¬¸ ê°ì²´ë¥¼ ê°œë³„ì ìœ¼ë¡œ íŒŒì‹± ì‹œë„
                remaining = content[bracket_start + 1:]
                question_objects = []
                
                # { ë¡œ ì‹œì‘í•˜ëŠ” ê°ì²´ë“¤ ì°¾ê¸°
                brace_count = 0
                current_obj = ""
                for char in remaining:
                    if char == '{':
                        if brace_count == 0:
                            current_obj = "{"
                        else:
                            current_obj += char
                        brace_count += 1
                    elif char == '}':
                        current_obj += char
                        brace_count -= 1
                        if brace_count == 0 and current_obj:
                            # ì™„ì„±ëœ ê°ì²´ íŒŒì‹± ì‹œë„
                            try:
                                question_obj = json.loads(current_obj)
                                if isinstance(question_obj, dict) and 'text' in question_obj:
                                    # ìµœì†Œ í•„ìˆ˜ í•„ë“œ ë³´ì™„
                                    if 'id' not in question_obj:
                                        question_obj['id'] = f"recovered_q_{len(question_objects) + 1}"
                                    if 'type' not in question_obj:
                                        question_obj['type'] = "multiple"
                                    if 'options' not in question_obj or not question_obj['options']:
                                        question_obj['options'] = [{"id": "opt_1", "text": "ê¸°íƒ€", "value": "other"}]
                                    
                                    question_objects.append(question_obj)
                                    logger.info(f"ğŸ”§ Recovered question object [{stream_id}]: {question_obj.get('text', '')[:50]}...")
                                    
                            except json.JSONDecodeError:
                                pass  # ê°œë³„ ê°ì²´ íŒŒì‹± ì‹¤íŒ¨ëŠ” ë¬´ì‹œ
                            current_obj = ""
                    else:
                        if brace_count > 0:
                            current_obj += char
                
                if question_objects:
                    logger.info(f"âœ… Partial recovery successful [{stream_id}]: {len(question_objects)} questions recovered")
                    return question_objects
        
        logger.warning(f"ğŸš¨ Partial recovery failed [{stream_id}]")
        return []
        
    except Exception as e:
        logger.error(f"ğŸš¨ Partial recovery error [{stream_id}]: {str(e)}")
        return []


# ì¸ë¼ì¸ í´ë°± ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜
async def generate_fallback_questions_inline(goal: str, intent_title: str, user_country: str, user_language: str, country_option: bool) -> str:
    """ìŠ¤íŠ¸ë¦¬ë° ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì™„ì „í•œ ì§ˆë¬¸ ìƒì„±"""
    try:
        logger.info(f"ğŸš€ Generating immediate fallback questions for: {goal} (intent: {intent_title})")
        
        # GeminiServiceì˜ ì¼ë°˜ APIë¡œ ì™„ì „í•œ ì§ˆë¬¸ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ì•„ë‹˜)
        questions = await gemini_service.generate_questions(
            goal=goal,
            intent_title=intent_title,
            user_country=user_country,
            user_language=user_language,
            country_option=country_option
        )
        
        if questions and len(questions) > 0:
            # ì™„ì „í•œ JSON í˜•íƒœë¡œ ë³€í™˜
            questions_data = [{
                "id": q.id,
                "text": q.text,
                "type": q.type,
                "options": [{
                    "id": opt.id,
                    "text": opt.text,
                    "value": opt.value
                } for opt in q.options] if hasattr(q, 'options') and q.options else [],
                "category": getattr(q, 'category', 'general')
            } for q in questions]
            
            fallback_json = json.dumps({"questions": questions_data}, ensure_ascii=False, indent=2)
            logger.info(f"âœ… Immediate fallback generated: {len(questions)} questions, {len(fallback_json)} chars")
            return fallback_json
        
    except Exception as e:
        logger.error(f"ğŸš¨ Immediate fallback generation failed: {str(e)}")
        
        # ìµœí›„ì˜ ìˆ˜ë‹¨: í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ ì§ˆë¬¸
        default_questions = {
            "questions": [
                {
                    "id": "default_q1",
                    "text": f"{intent_title}ì„(ë¥¼) ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
                    "type": "multiple",
                    "options": [
                        {"id": "opt_quality", "text": "í’ˆì§ˆê³¼ ì™„ì„±ë„", "value": "quality"},
                        {"id": "opt_speed", "text": "ë¹ ë¥¸ ì‹œì‘ê³¼ ì§„í–‰", "value": "speed"},
                        {"id": "opt_cost", "text": "ë¹„ìš© íš¨ìœ¨ì„±", "value": "cost"},
                        {"id": "opt_learning", "text": "í•™ìŠµê³¼ ê²½í—˜", "value": "learning"}
                    ],
                    "category": "priority"
                }
            ]
        }
        return json.dumps(default_questions, ensure_ascii=False, indent=2)
    
    return None

@router.post("/generate", response_model=QuestionGenerateResponse)
async def generate_questions(
    request: Request,
    question_request: QuestionGenerateRequest,
    current_user=Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ì„ íƒëœ ì˜ë„ì— ë”°ë¥¸ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± (POST)
    
    ë¹„ì¦ˆë‹ˆìŠ¤ íë¦„:
    1. ì„¸ì…˜ ìœ íš¨ì„± ê²€ì¦ (sessionId)
    2. Gemini APIë¥¼ í†µí•œ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± (goal + intentTitle ì‚¬ìš©)
    3. ì§ˆë¬¸ ì„¸íŠ¸ ID ìƒì„± ë° DB ì €ì¥
    4. í´ë¼ì´ì–¸íŠ¸ ì‘ë‹µ
    """
    try:
        # ìš”ì²­ì—ì„œ í•„ìˆ˜ ì •ë³´ ì¶”ì¶œ
        session_id = question_request.sessionId
        goal = question_request.goal
        intent_title = question_request.intentTitle
        user_country = question_request.userCountry  # í”„ë¡ íŠ¸ì—ì„œ ì „ë‹¬, None ê°€ëŠ¥
        user_language = question_request.userLanguage  # í”„ë¡ íŠ¸ì—ì„œ ì „ë‹¬, None ê°€ëŠ¥
        country_option = question_request.countryOption  # ì§€ì—­ì •ë³´ í¬í•¨ ì—¬ë¶€
        
        logger.info(f"Question generation request - Session: {session_id}, Goal: '{goal}', Intent: '{intent_title}', Country: {user_country}, Language: {user_language}, CountryOption: {country_option}")
        
        # 1. ì„¸ì…˜ ìœ íš¨ì„± ê²€ì¦ (ì˜ë„ ê²€ì¦ì€ ìƒëµ, ì§ì ‘ ì „ë‹¬ë°›ìŒ)
        is_valid, db_session, error_message = validate_session_basic(
            db, session_id
        )
        
        if not is_valid:
            logger.warning(f"Session validation failed: {error_message}")
            raise HTTPException(status_code=400, detail=error_message)
        
        # 2. Gemini APIë¥¼ í†µí•œ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± (ì„±ëŠ¥ ìµœì í™”ë¥¼ ìœ„í•´ êµ­ê°€ ê°ì§€ ì œê±°)
        logger.info(f"Generating questions for goal: '{goal}', intent: '{intent_title}'")
        
        try:
            questions = await gemini_service.generate_questions(
                goal=goal,
                intent_title=intent_title,
                user_country=user_country,
                user_language=user_language,
                country_option=country_option
            )
            
            logger.info(f"Generated {len(questions)} questions via Gemini API")
            
        except Exception as e:
            logger.error(f"Gemini question generation failed: {str(e)}")
            # ìºì‹œëœ í…œí”Œë¦¿ìœ¼ë¡œ ëŒ€ì²´ëŠ” ì´ë¯¸ ì„œë¹„ìŠ¤ ë‚´ë¶€ì—ì„œ ì²˜ë¦¬ë¨
            questions = await gemini_service.generate_questions(
                goal=goal,
                intent_title=intent_title,
                user_country=user_country,
                user_language=user_language,
                country_option=country_option
            )
        
        # 4. ì§ˆë¬¸ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
        if not questions or len(questions) == 0:
            logger.warning("No questions generated, using default template")
            questions = _get_emergency_questions()
        
        # 5. ì§ˆë¬¸ ì„¸íŠ¸ ID ìƒì„± ë° DB ì €ì¥
        questions_dict = [question.dict() for question in questions]
        question_set_id = save_question_set(
            db=db,
            session_id=session_id,
            intent_id=intent_title,  # intentTitleì„ intent_idë¡œ ì‚¬ìš©
            questions=questions_dict
        )
        
        logger.info(f"Saved question set with ID: {question_set_id}")
        
        # 6. ì„±ê³µ ì‘ë‹µ
        return QuestionGenerateResponse(questions=questions)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Unexpected error in question generation: {str(e)}")
        raise HTTPException(
            status_code=500, 
            detail="ì§ˆë¬¸ ìƒì„± ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

# ê³ ê¸‰ ì„±ëŠ¥ ìµœì í™” ìƒìˆ˜ ë° ìºì‹œ
_QUESTION_PATTERN_CACHE = {}
_BUFFER_SIZE_LIMIT = 8000  # ë²„í¼ í¬ê¸° ì œí•œ (10000 -> 8000)
_MIN_JSON_SIZE = 50  # ìµœì†Œ JSON í¬ê¸°
_SEARCH_WINDOW = 300  # ê²€ìƒ‰ ìœˆë„ìš° í¬ê¸°
_MAX_PARSE_ATTEMPTS = 3  # ìµœëŒ€ íŒŒì‹± ì‹œë„ íšŸìˆ˜
_CHUNK_BATCH_SIZE = 5  # ì²­í¬ ë°°ì¹˜ ì²˜ë¦¬ í¬ê¸°

# ë©”ëª¨ë¦¬ í’€ë§ì„ ìœ„í•œ ê°„ë‹¨í•œ ë²„í¼ ì¬ì‚¬ìš©
_buffer_pool = []
_MAX_POOL_SIZE = 5

def _get_buffer():
    """ë²„í¼ í’€ì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ë²„í¼ íšë“"""
    return _buffer_pool.pop() if _buffer_pool else ""

def _return_buffer(buffer: str):
    """ì‚¬ìš© ì™„ë£Œëœ ë²„í¼ë¥¼ í’€ì— ë°˜í™˜"""
    if len(_buffer_pool) < _MAX_POOL_SIZE and len(buffer) < _BUFFER_SIZE_LIMIT:
        _buffer_pool.append("")  # ì´ˆê¸°í™”í•˜ì—¬ ë°˜í™˜

async def _parse_questions_realtime(
    chunk: str,
    buffer: str,
    sent_question_ids: set,
    parsed_questions: list,
    question_count: int,
    stream_id: str
) -> tuple[dict, str, int] | None:
    """ê°œì„ ëœ ì‹¤ì‹œê°„ ì§ˆë¬¸ íŒŒì‹± - ëˆ„ë½ ë°©ì§€ ìµœì í™”
    
    ê°œì„  ì‚¬í•­:
    - ì „ì²´ ë²„í¼ ìŠ¤ìº”ìœ¼ë¡œ ëˆ„ë½ ë°©ì§€
    - ìˆœì°¨ì  ì§ˆë¬¸ ID ê²€ìƒ‰ (q1, q2, q3, q4, q5)
    - ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•œ sent_question_ids í™œìš©
    - ì•ˆì •ì ì¸ JSON íŒŒì‹±
    """
    try:
        # ë²„í¼ í¬ê¸° ê´€ë¦¬ (ë³´ìˆ˜ì  ì ‘ê·¼)
        if len(buffer) > _BUFFER_SIZE_LIMIT:
            # ìµœê·¼ ì ˆë°˜ë§Œ ìœ ì§€í•˜ì—¬ ì¤‘ê°„ ì§ˆë¬¸ ì†ì‹¤ ë°©ì§€
            buffer = buffer[len(buffer)//2:]
            logger.debug(f"Buffer trimmed conservatively [{stream_id}]")
        
        # ì „ì²´ ë²„í¼ ê²€ìƒ‰ (ëˆ„ë½ ë°©ì§€)
        working_buffer = buffer
        search_start = 0
        
        # ìˆœì°¨ì  ì§ˆë¬¸ ID ê²€ìƒ‰ (q1 -> q2 -> q3 -> q4 -> q5)
        question_ids_to_find = []
        for i in range(1, 8):  # q1ë¶€í„° q7ê¹Œì§€ í™•ì¸
            qid = f"q{i}"
            if qid not in sent_question_ids and qid in working_buffer:
                question_ids_to_find.append(qid)
        
        # ì°¾ì„ ì§ˆë¬¸ì´ ì—†ìœ¼ë©´ ì¢…ë£Œ
        if not question_ids_to_find:
            return None
        
        # ì²« ë²ˆì§¸ ë¯¸ë°œê²¬ ì§ˆë¬¸ ìš°ì„  ì²˜ë¦¬
        target_question_id = question_ids_to_find[0]
        logger.debug(f"Looking for {target_question_id} [{stream_id}]")
        
        # í•´ë‹¹ ì§ˆë¬¸ ID ìœ„ì¹˜ ì°¾ê¸°
        id_pattern = f'"id": "{target_question_id}"'
        id_pos = working_buffer.find(id_pattern)
        
        if id_pos == -1:
            return None
        
        # ì§ˆë¬¸ ê°ì²´ ì‹œì‘ì  ì°¾ê¸° (ì—­ë°©í–¥ ê²€ìƒ‰)
        search_start_pos = max(0, id_pos - 200)  # 200ì ì´ì „ë¶€í„° ê²€ìƒ‰
        obj_start = working_buffer.rfind('{', search_start_pos, id_pos)
        
        if obj_start == -1:
            return None
        
        # JSON ê°ì²´ ëì  ì°¾ê¸° (ìŠ¤íƒ ê¸°ë°˜ íŒŒì‹±)
        brace_stack = 0
        in_string = False
        escape_next = False
        obj_end = -1
        
        for j in range(obj_start, len(working_buffer)):
            current_char = working_buffer[j]
            
            # ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬
            if escape_next:
                escape_next = False
                continue
            
            if current_char == '\\':
                escape_next = True
                continue
            
            # ë¬¸ìì—´ ê²½ê³„ ì²˜ë¦¬
            if current_char == '"':
                in_string = not in_string
                continue
            
            # ë¸Œë ˆì´ìŠ¤ ì¹´ìš´íŒ… (ë¬¸ìì—´ ì™¸ë¶€ì—ì„œë§Œ)
            if not in_string:
                if current_char == '{':
                    brace_stack += 1
                elif current_char == '}':
                    brace_stack -= 1
                    
                    # ì™„ì „í•œ ê°ì²´ ë°œê²¬
                    if brace_stack == 0:
                        obj_end = j + 1
                        break
        
        if obj_end == -1:
            return None
        
        # JSON í›„ë³´ ì¶”ì¶œ ë° íŒŒì‹±
        candidate_json = working_buffer[obj_start:obj_end]
        
        try:
            question_obj = json.loads(candidate_json)
            
            # ì§ˆë¬¸ ê°ì²´ ê²€ì¦
            if (isinstance(question_obj, dict) and 
                'id' in question_obj and 
                'text' in question_obj and 
                'type' in question_obj and
                question_obj.get('id') == target_question_id):
                
                # ì¤‘ë³µ ë°©ì§€ ë° ìƒíƒœ ì—…ë°ì´íŠ¸
                sent_question_ids.add(target_question_id)
                parsed_questions.append(question_obj)
                question_count += 1
                
                logger.info(f"ğŸ“‹ Found {target_question_id} [{stream_id}]")
                
                # ë²„í¼ ì •ë¦¬ (ì²˜ë¦¬ëœ ë¶€ë¶„ ì œê±°)
                cleaned_buffer = working_buffer[obj_end:].lstrip()
                
                return question_obj, cleaned_buffer, question_count
                
        except (json.JSONDecodeError, KeyError, ValueError) as e:
            logger.debug(f"JSON parsing failed for {target_question_id} [{stream_id}]: {str(e)}")
            return None
                
    except Exception as e:
        logger.debug(f"Real-time parsing error [{stream_id}]: {str(e)}")
    
    return None

def _validate_question_object(question_obj: dict) -> bool:
    """ì§ˆë¬¸ ê°ì²´ ìœ íš¨ì„± ê²€ì¦ (í˜¸í™˜ì„± ìœ ì§€)"""
    return _validate_question_object_fast(question_obj)

def _validate_question_object_fast(question_obj: dict) -> bool:
    """ìµœì í™”ëœ ì§ˆë¬¸ ê°ì²´ ê²€ì¦ (ì¸ë¼ì¸ ê°€ëŠ¥)"""
    try:
        # ë¹ ë¥¸ íƒ€ì… ì²´í¬
        if not isinstance(question_obj, dict):
            return False
        
        # í•„ìˆ˜ í•„ë“œ ì›ìƒ· ì²´í¬
        if not ('id' in question_obj and 'text' in question_obj and 'type' in question_obj):
            return False
        
        q_type = question_obj.get('type')
        
        # ì„ íƒí˜• ì§ˆë¬¸ ê²€ì¦ (ìµœì í™”)
        if q_type in ('single', 'multiple'):
            options = question_obj.get('options')
            if not options or not isinstance(options, list):
                return False
            # ì²« ë²ˆì§¸ ì˜µì…˜ë§Œ ì²´í¬ (ì„±ëŠ¥)
            if len(options) > 0 and not isinstance(options[0], dict):
                return False
        
        return True
    except:
        return False

def _get_emergency_questions() -> list[Question]:
    """ë¹„ìƒìš© ê¸°ë³¸ ì§ˆë¬¸ í…œí”Œë¦¿"""
    return [
        Question(
            id="q_emergency_1",
            text="ì–¸ì œê¹Œì§€ ì´ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
            type="multiple",
            options=[
                Option(id="opt_1week", text="1ì£¼ì¼ ë‚´", value="1week"),
                Option(id="opt_1month", text="1ë‹¬ ë‚´", value="1month"),
                Option(id="opt_3months", text="3ë‹¬ ë‚´", value="3months"),
                Option(id="opt_flexible", text="ìœ ì—°í•˜ê²Œ", value="flexible")
            ],
            required=True
        ),
        Question(
            id="q_emergency_2",
            text="ì´ ëª©í‘œë¥¼ ìœ„í•´ íˆ¬ìí•  ìˆ˜ ìˆëŠ” ìì›ì€?",
            type="multiple",
            options=[
                Option(id="opt_time", text="ì£¼ë¡œ ì‹œê°„", value="time"),
                Option(id="opt_money", text="ì£¼ë¡œ ëˆ", value="money"),
                Option(id="opt_both", text="ì‹œê°„ê³¼ ëˆ ëª¨ë‘", value="both"),
                Option(id="opt_minimal", text="ìµœì†Œí•œë§Œ", value="minimal")
            ],
            required=True
        ),
        Question(
            id="q_emergency_3",
            text="ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒì€?",
            type="multiple",
            options=[
                Option(id="opt_speed", text="ë¹ ë¥¸ ë‹¬ì„±", value="speed"),
                Option(id="opt_quality", text="ë†’ì€ í’ˆì§ˆ", value="quality"),
                Option(id="opt_cost", text="ë¹„ìš© ì ˆì•½", value="cost"),
                Option(id="opt_balance", text="ê· í˜•ì¡íŒ ì ‘ê·¼", value="balance")
            ],
            required=True
        )
    ]

@router.post("/answer", response_model=QuestionAnswersResponse)
async def submit_answers(
    request: QuestionAnswersRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ëª¨ë“  ë‹µë³€ì„ í•œë²ˆì— ì œì¶œí•˜ì—¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
    
    ë¹„ì¦ˆë‹ˆìŠ¤ íë¦„:
    1. ìš”ì²­ ë°ì´í„° ê²€ì¦ (goal, selectedIntent, answers)
    2. ì‚¬ìš©ì ë‹µë³€ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    3. Gemini AIë¥¼ í†µí•œ ê¸°ë³¸ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±
    4. Gemini APIë¥¼ í†µí•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ê°¯ìˆ˜ì— ë”°ë¥¸ ë³‘ë ¬ ê²€ìƒ‰ ì‹¤í–‰
    5. ê²€ìƒ‰ ê²°ê³¼ì™€ AI ìƒì„± ê²°ê³¼ ë³‘í•© ë° ë³´ê°•
    6. ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    7. ì²´í¬ë¦¬ìŠ¤íŠ¸ ID ë° ë¦¬ë‹¤ì´ë ‰íŠ¸ URL ë°˜í™˜
    """
    try:
        # ìš”ì²­ ë°ì´í„° ë¡œê¹…
        logger.info(f"Answer submission request - User: {current_user.id}, Goal: '{request.goal}', Intent: '{request.selectedIntent}', Answers: {len(request.answers)}")
        
        # ì…ë ¥ ë°ì´í„° ê²€ì¦
        if not request.goal.strip():
            raise HTTPException(status_code=400, detail="ëª©í‘œ(goal)ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
        
        if not request.selectedIntent.strip():
            raise HTTPException(status_code=400, detail="ì„ íƒëœ ì˜ë„(selectedIntent)ëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤.")
        
        if not request.answers or len(request.answers) == 0:
            raise HTTPException(status_code=400, detail="ë‹µë³€(answers)ì€ ìµœì†Œ 1ê°œ ì´ìƒ í•„ìš”í•©ë‹ˆë‹¤.")
        
        # ë‹µë³€ ë‚´ìš© ê²€ì¦
        for i, answer in enumerate(request.answers):
            if not answer.questionText.strip():
                raise HTTPException(status_code=400, detail=f"ì§ˆë¬¸ {i+1}ì˜ ë‚´ìš©ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            # answerê°€ ë¬¸ìì—´ì´ê±°ë‚˜ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
            if not answer.answer:
                raise HTTPException(status_code=400, detail=f"ì§ˆë¬¸ {i+1}ì˜ ë‹µë³€ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
            
            if isinstance(answer.answer, list) and len(answer.answer) == 0:
                raise HTTPException(status_code=400, detail=f"ì§ˆë¬¸ {i+1}ì˜ ë‹µë³€ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        
        logger.info(f"Request validation successful for user {current_user.id}")
        
        # ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ì‹¤í–‰
        try:
            response = await checklist_orchestrator.process_answers_to_checklist(
                request=request,
                user=current_user,
                db=db
            )
            
            logger.info(f"Checklist generation successful: {response.checklistId}")
            return response
            
        except ChecklistGenerationError as e:
            logger.error(f"Checklist generation error for user {current_user.id}: {str(e)}")
            raise HTTPException(status_code=500, detail=str(e))
        
        except Exception as e:
            logger.error(f"Unexpected error during checklist generation: {str(e)}")
            raise HTTPException(
                status_code=500, 
                detail="ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            )
    
    except HTTPException:
        # FastAPI HTTPExceptionì€ ê·¸ëŒ€ë¡œ ì „íŒŒ
        raise
    
    except Exception as e:
        # ì˜ˆìƒì¹˜ ëª»í•œ ëª¨ë“  ì˜¤ë¥˜ ì²˜ë¦¬
        logger.error(f"Unexpected error in submit_answers endpoint: {str(e)}")
        raise HTTPException(
            status_code=500, 
            detail="ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•´ì£¼ì„¸ìš”."
        )

@router.post("/answer/stream")
async def submit_answers_stream(
    request: Request,
    question_request: QuestionAnswersRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ë‹µë³€ì„ ì œì¶œí•˜ì—¬ ì²´í¬ë¦¬ìŠ¤íŠ¸ë¥¼ ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ìƒì„±
    
    ë¹„ì¦ˆë‹ˆìŠ¤ íë¦„:
    1. ìš”ì²­ ë°ì´í„° ê²€ì¦ ë° ì‹œì‘ ìƒíƒœ ì „ì†¡
    2. ì‚¬ìš©ì ë‹µë³€ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
    3. ì²´í¬ë¦¬ìŠ¤íŠ¸ ì•„ì´í…œì„ í•˜ë‚˜ì”© ìƒì„±í•˜ë©° ì‹¤ì‹œê°„ ì „ì†¡
    4. ê° ì•„ì´í…œì— ëŒ€í•œ ê²€ìƒ‰ ê²°ê³¼ ë³´ê°• ë° ì „ì†¡
    5. ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸ DB ì €ì¥ ë° ì™„ë£Œ ì‹ í˜¸
    """
    import uuid
    import asyncio
    
    # ìŠ¤íŠ¸ë¦¼ ID ìƒì„±
    stream_id = str(uuid.uuid4())[:8]
    
    try:
        logger.info(f"ğŸŒŠ Starting checklist streaming [{stream_id}] - User: {current_user.id}, Goal: '{question_request.goal}'")
        
        async def checklist_stream():
            try:
                # 1. ì‹œì‘ ìƒíƒœ ì „ì†¡
                start_data = {
                    "status": "started",
                    "message": "ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤",
                    "stream_id": stream_id,
                    "goal": question_request.goal,
                    "intent": question_request.selectedIntent
                }
                yield f"data: {json.dumps(start_data, ensure_ascii=False)}\n\n"
                
                # 2. ë‹µë³€ ì €ì¥ ìƒíƒœ
                save_data = {
                    "status": "saving_answers",
                    "message": "ë‹µë³€ì„ ì €ì¥í•˜ê³  ìˆìŠµë‹ˆë‹¤",
                    "answers_count": len(question_request.answers)
                }
                yield f"data: {json.dumps(save_data, ensure_ascii=False)}\n\n"
                
                # 3. ì‹¤ì œ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± (checklist_orchestrator ì‚¬ìš©)
                try:
                    # async generatorì´ë¯€ë¡œ await ì—†ì´ ì§ì ‘ iterate
                    result_stream = checklist_orchestrator.process_answers_to_checklist_stream(
                        question_request, current_user, db, stream_id
                    )
                    
                    # 4. ìŠ¤íŠ¸ë¦¬ë° ì¤‘ê°„ì— ê° ì•„ì´í…œë“¤ì´ ì „ì†¡ë¨ (orchestratorì—ì„œ ì²˜ë¦¬)
                    async for item_data in result_stream:
                        yield f"data: {json.dumps(item_data, ensure_ascii=False)}\n\n"
                        
                except Exception as orchestrator_error:
                    logger.error(f"ğŸš¨ Checklist orchestrator failed [{stream_id}]: {str(orchestrator_error)}")
                    
                    # ì—ëŸ¬ ìƒíƒœ ì „ì†¡
                    error_data = {
                        "status": "error",
                        "message": "ì²´í¬ë¦¬ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                        "error": str(orchestrator_error),
                        "stream_id": stream_id
                    }
                    yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                    yield f"data: [DONE]\n\n"
                    return
                
                # 5. ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ
                yield f"data: [DONE]\n\n"
                
            except Exception as e:
                logger.error(f"ğŸš¨ Checklist streaming error [{stream_id}]: {str(e)}")
                error_data = {
                    "status": "error",
                    "message": "ìŠ¤íŠ¸ë¦¬ë° ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤",
                    "error": str(e),
                    "stream_id": stream_id
                }
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                yield f"data: [DONE]\n\n"
        
        # CORS í—¤ë” ì„¤ì •
        cors_headers = get_cors_headers(request)
        streaming_headers = {
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Pragma": "no-cache",
            "Expires": "0",
            "Access-Control-Allow-Origin": cors_headers.get("Access-Control-Allow-Origin", "https://nowwhat-front.vercel.app"),
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type, Authorization, Accept, X-Requested-With",
            "Access-Control-Allow-Credentials": "true",
            "Access-Control-Expose-Headers": "*"
        }
        streaming_headers.update(cors_headers)
        
        response = StreamingResponse(
            checklist_stream(),
            media_type="text/plain; charset=utf-8",
            headers=streaming_headers
        )
        
        # ì¶”ê°€ CORS í—¤ë” ì„¤ì •
        response.headers["Access-Control-Allow-Origin"] = cors_headers.get("Access-Control-Allow-Origin", "https://nowwhat-front.vercel.app")
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, Accept, X-Requested-With"
        response.headers["Access-Control-Allow-Credentials"] = "true"
        response.headers["Access-Control-Expose-Headers"] = "*"
        response.headers["Vary"] = "Origin"
        
        return response
        
    except Exception as e:
        logger.error(f"ğŸš¨ Top-level checklist streaming error [{stream_id}]: {str(e)}")
        raise HTTPException(
            status_code=500,
            detail="ì²´í¬ë¦¬ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
        )

@router.options("/answer/stream")
async def options_submit_answers_stream(request: Request):
    """ì²´í¬ë¦¬ìŠ¤íŠ¸ ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìœ„í•œ í”„ë¦¬í”Œë¼ì´íŠ¸ CORS ì²˜ë¦¬"""
    cors_headers = get_cors_headers(request)
    return Response(
        status_code=200,
        headers={
            **cors_headers,
            "Access-Control-Allow-Methods": "POST, OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type, Authorization, Accept, X-Requested-With",
            "Access-Control-Max-Age": "86400"
        }
    )

@router.options("/generate/stream")
async def options_generate_questions_stream(request: Request):
    """ìŠ¤íŠ¸ë¦¬ë° ì—”ë“œí¬ì¸íŠ¸ë¥¼ ìœ„í•œ í”„ë¦¬í”Œë¼ì´íŠ¸ CORS ì²˜ë¦¬"""
    return Response(
        status_code=200,
        headers=get_cors_headers(request)
    )

@router.post("/generate/stream")
async def generate_questions_stream(
    request: Request,
    question_request: QuestionGenerateRequest,
    current_user=Depends(get_current_user),
    db: Session = Depends(get_db)
):
    """ì„ íƒëœ ì˜ë„ì— ë”°ë¥¸ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± (ìŠ¤íŠ¸ë¦¬ë° ë²„ì „)
    
    Server-Sent Events (SSE) í˜•ì‹ìœ¼ë¡œ ì‹¤ì‹œê°„ ì‘ë‹µì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    stream_id = None
    try:
        # ìš”ì²­ì—ì„œ í•„ìˆ˜ ì •ë³´ ì¶”ì¶œ
        session_id = question_request.sessionId
        goal = question_request.goal
        intent_title = question_request.intentTitle
        user_country = question_request.userCountry
        user_language = question_request.userLanguage
        country_option = question_request.countryOption
        
        # ìŠ¤íŠ¸ë¦¬ë° ìš”ì²­ ê³ ìœ  ID ìƒì„±
        stream_id = str(uuid.uuid4())[:8]
        logger.info(f"ğŸŒŠ API: Streaming request [{stream_id}] - Session: {session_id}, Goal: '{goal}', Intent: '{intent_title}', CountryOption: {country_option}")
        
        # 1. ì„¸ì…˜ ìœ íš¨ì„± ê²€ì¦
        is_valid, db_session, error_message = validate_session_basic(db, session_id)
        
        if not is_valid:
            logger.warning(f"Session validation failed: {error_message}")
            
            async def error_stream():
                error_data = {"error": error_message, "status": "error"}
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                yield f"data: [DONE]\n\n"
            
            cors_headers = get_cors_headers(request)
            streaming_headers = {
                "Cache-Control": "no-cache, no-store, must-revalidate",
                "Connection": "keep-alive",
                "X-Accel-Buffering": "no",
                "Pragma": "no-cache",
                "Expires": "0"
            }
            streaming_headers.update(cors_headers)
            
            # ì—ëŸ¬ ì‘ë‹µì—ë„ CORS í—¤ë” ê°•í™”
            response = StreamingResponse(
                error_stream(),
                media_type="text/plain; charset=utf-8",
                headers=streaming_headers
            )
            
            # ì¶”ê°€ì ìœ¼ë¡œ CORS í—¤ë” ì§ì ‘ ì„¤ì •
            response.headers["Access-Control-Allow-Origin"] = cors_headers.get("Access-Control-Allow-Origin", "https://nowwhat-front.vercel.app")
            response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
            response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, Accept, X-Requested-With"
            response.headers["Access-Control-Allow-Credentials"] = "true"
            
            return response
        
        # 2. ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ìƒì„± (Vercel ì„œë²„ë¦¬ìŠ¤ í™˜ê²½ ìµœì í™”)
        async def question_stream():
            accumulated_content = ""
            try:
                # Pro Plan í™˜ê²½ ìµœì í™”
                is_vercel = os.getenv("VERCEL") == "1"
                logger.info(f"ğŸŒŠ Environment detection [{stream_id}]: Vercel={is_vercel} (Pro Plan)")
                
                # ì‹œì‘ ì‹ í˜¸
                start_data = {"status": "started", "message": f"ì§ˆë¬¸ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤... [{stream_id}]"}
                yield f"data: {json.dumps(start_data, ensure_ascii=False)}\n\n"
                
                # ì—°ê²° ìƒíƒœ ì²´í¬ë¥¼ ìœ„í•œ ì´ˆê¸° flush
                await asyncio.sleep(0.1)
                
                # Pro Planì—ì„œ ì‹¤ì œ ìŠ¤íŠ¸ë¦¬ë° ì‹œë„ (ë” ê³µê²©ì ìœ¼ë¡œ)
                logger.info(f"ğŸŒŠ Pro Plan streaming attempt [{stream_id}]")
                
                # ê³ ì„±ëŠ¥ íŒŒì„œ ìƒíƒœ ì´ˆê¸°í™”
                parsed_questions = []
                current_question_buffer = _get_buffer()  # ë²„í¼ í’€ ì‚¬ìš©
                question_count = 0
                sent_question_ids = set()  # ì¤‘ë³µ ì „ì†¡ ë°©ì§€
                parse_attempts = 0  # íŒŒì‹± ì‹œë„ íšŸìˆ˜ ì œí•œ
                
                # Gemini ìŠ¤íŠ¸ë¦¬ë° í˜¸ì¶œ (Pro Plan ìµœì í™”, íƒ€ì„ì•„ì›ƒ ë³´í˜¸)
                try:
                    streaming_task = gemini_service.generate_questions_stream(
                        goal=goal,
                        intent_title=intent_title,
                        user_country=user_country,
                        user_language=user_language,
                        country_option=country_option
                    )
                    
                    # íƒ€ì„ì•„ì›ƒì„ ê°€ì§„ ìŠ¤íŠ¸ë¦¬ë° ì²˜ë¦¬
                    start_time = asyncio.get_event_loop().time()
                    chunk_counter = 0
                    async for chunk in streaming_task:
                        # 90ì´ˆ íƒ€ì„ì•„ì›ƒ ì²´í¬
                        if asyncio.get_event_loop().time() - start_time > 90:
                            logger.warning(f"ğŸ•’ Manual timeout triggered [{stream_id}]")
                            raise asyncio.TimeoutError("Manual timeout after 90 seconds")
                        
                        chunk_counter += 1
                        
                        # ì¤‘ìš”í•œ ì²­í¬ë§Œ ë¡œê¹… (ì„±ëŠ¥ ìµœì í™”)
                        if chunk_counter <= 2 or ('q1' in chunk and question_count == 0):
                            logger.info(f"ğŸ”¥ Chunk #{chunk_counter} [{stream_id}]: {chunk[:80]}...")
                        
                        accumulated_content += chunk
                        current_question_buffer += chunk
                        
                        # ì²« ë²ˆì§¸ ì§ˆë¬¸ ê°ì§€ë¥¼ ìœ„í•œ ì¶”ê°€ ë¡œê¹…
                        if question_count == 0 and '"id": "q1"' in current_question_buffer:
                            logger.info(f"ğŸ¯ First question (q1) detected in buffer [{stream_id}]")
                        
                        # ìµœì í™”ëœ íŒŒì‹± íŠ¸ë¦¬ê±° ë¡œì§ v2
                        should_parse = False
                        
                        # íš¨ìœ¨ì  íŠ¸ë¦¬ê±° íŒë‹¨
                        if '}' in chunk:  # ê°€ì¥ ì¤‘ìš”í•œ íŠ¸ë¦¬ê±°
                            should_parse = True
                        elif question_count == 0 and len(current_question_buffer) > 50:  # q1 ìš°ì„ 
                            should_parse = True
                        elif len(current_question_buffer) > 200 and ('"id":' in chunk or '"type":' in chunk):
                            should_parse = True
                        
                        if should_parse:
                            # ë¹„ë™ê¸° íŒŒì‹± í˜¸ì¶œ (ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”)
                            try:
                                parsed_question = await _parse_questions_realtime(
                                    chunk, current_question_buffer, sent_question_ids, 
                                    parsed_questions, question_count, stream_id
                                )
                            except Exception as parse_error:
                                logger.debug(f"Parse error [{stream_id}]: {parse_error}")
                                parsed_question = None
                        else:
                            parsed_question = None
                        
                        if parsed_question:
                            question_obj, new_buffer, updated_count = parsed_question
                            current_question_buffer = new_buffer
                            question_count = updated_count
                            
                            # ì´ˆê³ ì† ì „ì†¡ (ì‹œê°„ ì œê±°)
                            single_question_data = {
                                "status": "question_ready",
                                "question": question_obj,
                                "question_number": question_count
                            }
                            
                            # JSON ì§ë ¬í™” ìµœì í™” (separators ì‚¬ìš©)
                            json_str = json.dumps(single_question_data, ensure_ascii=False, separators=(',', ':'))
                            yield f"data: {json_str}\n\n"
                            
                            # ì¡°ê±´ë¶€ ë¡œê¹… (ì²« 2ê°œë§Œ)
                            if question_count <= 2:
                                logger.info(f"ğŸ“¤ Q{question_count} sent [{stream_id}]")
                        
                        # CPU ì–‘ë³´ ë° ì´ë²¤íŠ¸ ë£¨í”„ ì²˜ë¦¬ (ìµœì í™”)
                        # ë§¤ 5ë²ˆì§¸ ì²­í¬ë§ˆë‹¤ë§Œ CPU ì–‘ë³´
                        if chunk_counter % 5 == 0:
                            await asyncio.sleep(0)
                            
                except (asyncio.TimeoutError, OSError, BrokenPipeError) as timeout_error:
                    logger.warning(f"ğŸ•’ Streaming timeout or connection lost [{stream_id}]: {str(timeout_error)}")
                    
                    # íƒ€ì„ì•„ì›ƒ ì‹œ ì¦‰ì‹œ í´ë°± ë°ì´í„° ìƒì„±
                    fallback_content = await generate_fallback_questions_inline(
                        goal, intent_title, user_country, user_language, country_option
                    )
                    if fallback_content:
                        yield f"data: {json.dumps({'status': 'timeout_recovery', 'chunk': fallback_content}, ensure_ascii=False)}\n\n"
                        accumulated_content = fallback_content
                    else:
                        # ìµœí›„ì˜ ìˆ˜ë‹¨
                        error_data = {"status": "error", "message": "ìŠ¤íŠ¸ë¦¬ë° íƒ€ì„ì•„ì›ƒì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì¼ë°˜ APIë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”."}
                        yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                        return
                
                logger.info(f"ğŸŒŠ Primary stream completed [{stream_id}], accumulated: {len(accumulated_content)} chars, questions sent: {question_count}")
                
                # ì‹¤ì‹œê°„ íŒŒì‹±ìœ¼ë¡œ ì§ˆë¬¸ë“¤ì´ ì „ì†¡ëœ ê²½ìš°
                if len(parsed_questions) > 0:
                    # q1 ëˆ„ë½ ì²´í¬ ë° ìë™ ë³µêµ¬
                    sent_ids = [q.get('id') for q in parsed_questions]
                    if 'q1' not in sent_ids and '"id": "q1"' in accumulated_content:
                        logger.warning(f"âš ï¸ q1 missing, attempting recovery [{stream_id}]")
                        
                        # q1 ê¸´ê¸‰ ë³µêµ¬ ì‹œë„
                        q1_start = accumulated_content.find('{', accumulated_content.find('"id": "q1"') - 50)
                        if q1_start >= 0:
                            q1_search = accumulated_content[q1_start:q1_start + 2000]
                            # ë¹ ë¥¸ q1 ì¶”ì¶œ ì‹œë„
                            if '{' in q1_search and '}' in q1_search:
                                try:
                                    # q1ë§Œ íŒŒì‹±í•´ë³´ê¸°
                                    temp_parsed = await _parse_questions_realtime(
                                        '', q1_search, set(), [], 0, stream_id
                                    )
                                    if temp_parsed and temp_parsed[0].get('id') == 'q1':
                                        # q1 ë³µêµ¬ ì„±ê³µ - ë§¨ ì•ì— ì‚½ì…
                                        parsed_questions.insert(0, temp_parsed[0])
                                        logger.info(f"âœ… q1 successfully recovered [{stream_id}]")
                                except:
                                    pass
                    
                    logger.info(f"âœ… Real-time parsing successful [{stream_id}]: {len(parsed_questions)} questions sent")
                    # ì™„ë£Œ ì‹ í˜¸ (ì •ìƒ) - ì§ˆë¬¸ë³„ ìŠ¤íŠ¸ë¦¬ë° ì„±ê³µ
                    complete_data = {
                        "status": "completed", 
                        "message": f"ì§ˆë¬¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. [{stream_id}]",
                        "validated": True,
                        "total_questions": len(parsed_questions),
                        "streaming_mode": "per_question"
                    }
                    yield f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n"
                else:
                    # ì‹¤ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨ì‹œ batch_fallback ëª¨ë“œë¡œ ì²˜ë¦¬
                    logger.info(f"ğŸ” Real-time parsing failed, trying batch processing [{stream_id}]")
                    
                    # ì „ì²´ JSON ì™„ì „ì„± ê²€ì¦ ì‹œë„
                    is_complete, full_parsed_questions = await verify_and_fix_json_completeness(accumulated_content, stream_id)
                    
                    if is_complete and full_parsed_questions:
                        logger.info(f"âœ… Batch processing successful [{stream_id}]: {len(full_parsed_questions)} questions")
                        
                        # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ì´ë¯¸ ì „ì†¡ëœ ì§ˆë¬¸ ì œì™¸
                        new_questions = []
                        for question in full_parsed_questions:
                            question_id = question.get('id')
                            if question_id not in sent_question_ids:
                                new_questions.append(question)
                                sent_question_ids.add(question_id)
                        
                        # ìƒˆë¡œìš´ ì§ˆë¬¸ë“¤ë§Œ ì „ì†¡
                        for idx, question in enumerate(new_questions):
                            question_count += 1
                            question_data = {
                                "status": "question_ready",
                                "question": question,
                                "question_number": question_count,
                                "batch_mode": True
                            }
                            yield f"data: {json.dumps(question_data, ensure_ascii=False)}\n\n"
                        
                        total_questions = len(parsed_questions) + len(new_questions)
                        complete_data = {
                            "status": "completed",
                            "message": f"ì§ˆë¬¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. [{stream_id}]",
                            "total_questions": total_questions,
                            "streaming_mode": "batch_processing"
                        }
                        yield f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n"
                    else:
                        # íŒŒì‹± ë¶ˆê°€ëŠ¥í•œ ê²½ìš° - ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš© (API í˜¸ì¶œ ì—†ì´)
                        logger.info(f"ğŸ”„ Using default template due to corrupted stream [{stream_id}]")
                        
                        # í•˜ë“œì½”ë”©ëœ ê¸°ë³¸ ì§ˆë¬¸ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ì „ì†¡
                        default_questions_list = [
                        {
                            "id": "q_default_1",
                            "text": f"{intent_title}ì„(ë¥¼) ìœ„í•´ ì–¸ì œê¹Œì§€ ëª©í‘œë¥¼ ë‹¬ì„±í•˜ê³  ì‹¶ìœ¼ì‹ ê°€ìš”?",
                            "type": "multiple",
                            "options": [
                                {"id": "opt_1week", "text": "1ì£¼ì¼ ë‚´", "value": "1week"},
                                {"id": "opt_1month", "text": "1ë‹¬ ë‚´", "value": "1month"},
                                {"id": "opt_3months", "text": "3ë‹¬ ë‚´", "value": "3months"},
                                {"id": "opt_flexible", "text": "ìœ ì—°í•˜ê²Œ", "value": "flexible"}
                            ],
                            "category": "timeline"
                        },
                        {
                            "id": "q_default_2",
                            "text": "ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì¸ê°€ìš”?",
                            "type": "multiple",
                            "options": [
                                {"id": "opt_quality", "text": "í’ˆì§ˆê³¼ ì™„ì„±ë„", "value": "quality"},
                                {"id": "opt_speed", "text": "ë¹ ë¥¸ ì‹œì‘", "value": "speed"},
                                {"id": "opt_cost", "text": "ë¹„ìš© íš¨ìœ¨", "value": "cost"},
                                {"id": "opt_learning", "text": "í•™ìŠµê³¼ ê²½í—˜", "value": "learning"}
                            ],
                            "category": "priority"
                        }
                        ]
                        
                        # ê¸°ë³¸ ì§ˆë¬¸ë“¤ì„ ê°œë³„ì ìœ¼ë¡œ ì „ì†¡
                        for idx, question in enumerate(default_questions_list):
                            question_data = {
                                "status": "question_ready",
                                "question": question,
                                "question_number": idx + 1,
                                "default_template": True
                            }
                            yield f"data: {json.dumps(question_data, ensure_ascii=False)}\n\n"
                        
                        # ì–´ë–¤ ê²½ìš°ë“  ì‚¬ìš©ìëŠ” ì™„ì „í•œ ë°ì´í„°ë¥¼ ë°›ì•˜ë‹¤ê³  ì•Œë¦¼
                        complete_data = {
                            "status": "completed",
                            "message": f"ì§ˆë¬¸ ìƒì„±ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. [{stream_id}]",
                            "total_questions": len(default_questions_list),
                            "streaming_mode": "default_template"
                        }
                        yield f"data: {json.dumps(complete_data, ensure_ascii=False)}\n\n"
                
                # [DONE] ì‹ í˜¸ ì¦‰ì‹œ ì „ì†¡ (ë¶ˆí•„ìš”í•œ ëŒ€ê¸° ì œê±°)
                yield f"data: [DONE]\n\n"
                
                # ë©”ëª¨ë¦¬ ì •ë¦¬ ë° ë²„í¼ í’€ ë°˜í™˜
                try:
                    _return_buffer(current_question_buffer)
                except:
                    pass  # ì—ëŸ¬ ë¬´ì‹œ
                
            except Exception as e:
                logger.error(f"ğŸš¨ Enhanced streaming error [{stream_id}]: {str(e)}")
                import traceback
                logger.error(f"ğŸš¨ Stack trace [{stream_id}]: {traceback.format_exc()}")
                
                # ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜ ì‹œì—ë„ ì™„ì „í•œ ì§ˆë¬¸ ì œê³µ ì‹œë„
                try:
                    fallback_content = await generate_fallback_questions_inline(
                        goal, intent_title, user_country, user_language, country_option
                    )
                    if fallback_content:
                        yield f"data: {json.dumps({'status': 'error_recovery', 'chunk': fallback_content}, ensure_ascii=False)}\n\n"
                        yield f"data: {json.dumps({'status': 'completed', 'message': 'ì˜¤ë¥˜ ë³µêµ¬ ì™„ë£Œ'}, ensure_ascii=False)}\n\n"
                        yield f"data: [DONE]\n\n"
                        return
                except:
                    pass  # í´ë°±ë„ ì‹¤íŒ¨í•˜ë©´ ì•„ë˜ ì˜¤ë¥˜ ì‘ë‹µìœ¼ë¡œ
                
                error_data = {
                    "status": "error", 
                    "error": str(e),
                    "stream_id": stream_id,
                    "accumulated_chars": len(accumulated_content),
                    "recovery_suggestion": "ë¹„ìŠ¤íŠ¸ë¦¬ë° ë²„ì „(ì¼ë°˜ API)ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
                }
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
                yield f"data: [DONE]\n\n"
        
        # CORS í—¤ë”ì™€ ìŠ¤íŠ¸ë¦¬ë° í—¤ë” í•©ì¹˜ê¸° - ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ê°•í™”
        cors_headers = get_cors_headers(request)
        streaming_headers = {
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",  # Nginx ë²„í¼ë§ ë¹„í™œì„±í™”
            "Pragma": "no-cache",
            "Expires": "0",
            # CORS í—¤ë”ë¥¼ ìŠ¤íŠ¸ë¦¬ë° í—¤ë”ì— ì§ì ‘ í¬í•¨
            "Access-Control-Allow-Origin": cors_headers.get("Access-Control-Allow-Origin", "https://nowwhat-front.vercel.app"),
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS", 
            "Access-Control-Allow-Headers": "Content-Type, Authorization, Accept, X-Requested-With",
            "Access-Control-Allow-Credentials": "true",
            "Access-Control-Expose-Headers": "*"
        }
        
        # ë¸Œë¼ìš°ì € í˜¸í™˜ì„±ì„ ìœ„í•œ ì¶”ê°€ í—¤ë”
        streaming_headers.update(cors_headers)
        
        response = StreamingResponse(
            question_stream(),
            media_type="text/plain; charset=utf-8",
            headers=streaming_headers
        )
        
        # ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ê°•í™” - ì¤‘ë³µì´ì§€ë§Œ í™•ì‹¤í•˜ê²Œ ì„¤ì •
        response.headers["Access-Control-Allow-Origin"] = cors_headers.get("Access-Control-Allow-Origin", "https://nowwhat-front.vercel.app")
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, Accept, X-Requested-With"
        response.headers["Access-Control-Allow-Credentials"] = "true"
        response.headers["Access-Control-Expose-Headers"] = "*"
        response.headers["Vary"] = "Origin"
        
        return response
        
    except Exception as e:
        import traceback
        error_detail = f"Streaming error: {str(e)}\nTraceback: {traceback.format_exc()}"
        logger.error(f"ğŸš¨ Top-level streaming error [{stream_id}]: {error_detail}")
        
        # ìµœìƒìœ„ ì˜ˆì™¸ì—ì„œë„ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µìœ¼ë¡œ ì²˜ë¦¬
        async def error_recovery_stream():
            try:
                # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ì™„ì „í•œ ì§ˆë¬¸ ì œê³µ ì‹œë„
                fallback_content = await generate_fallback_questions_inline(
                    question_request.goal, 
                    question_request.intentTitle,
                    question_request.userCountry, 
                    question_request.userLanguage, 
                    question_request.countryOption
                )
                if fallback_content:
                    yield f"data: {json.dumps({'status': 'emergency_recovery', 'chunk': fallback_content}, ensure_ascii=False)}\n\n"
                    yield f"data: {json.dumps({'status': 'completed', 'message': 'ê¸´ê¸‰ ë³µêµ¬ ì™„ë£Œ'}, ensure_ascii=False)}\n\n"
                else:
                    # ìµœí›„ì˜ ìˆ˜ë‹¨
                    error_data = {"status": "error", "message": "ì„œë²„ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}
                    yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
            except:
                error_data = {"status": "error", "message": "ì‹¬ê°í•œ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. í˜ì´ì§€ë¥¼ ìƒˆë¡œê³ ì¹¨í•´ì£¼ì„¸ìš”."}
                yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
            finally:
                yield f"data: [DONE]\n\n"
        
        # CORS í—¤ë” í¬í•¨í•œ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ - ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ê°•í™”
        cors_headers = get_cors_headers(request)
        streaming_headers = {
            "Cache-Control": "no-cache, no-store, must-revalidate",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no",
            "Pragma": "no-cache",
            "Expires": "0",
            # CORS í—¤ë”ë¥¼ ìŠ¤íŠ¸ë¦¬ë° í—¤ë”ì— ì§ì ‘ í¬í•¨
            "Access-Control-Allow-Origin": cors_headers.get("Access-Control-Allow-Origin", "https://nowwhat-front.vercel.app"),
            "Access-Control-Allow-Methods": "GET, POST, PUT, DELETE, OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type, Authorization, Accept, X-Requested-With",
            "Access-Control-Allow-Credentials": "true",
            "Access-Control-Expose-Headers": "*"
        }
        streaming_headers.update(cors_headers)
        
        response = StreamingResponse(
            error_recovery_stream(),
            media_type="text/plain; charset=utf-8",
            headers=streaming_headers
        )
        
        # ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ê°•í™” - ì¤‘ë³µì´ì§€ë§Œ í™•ì‹¤í•˜ê²Œ ì„¤ì •
        response.headers["Access-Control-Allow-Origin"] = cors_headers.get("Access-Control-Allow-Origin", "https://nowwhat-front.vercel.app")
        response.headers["Access-Control-Allow-Methods"] = "GET, POST, PUT, DELETE, OPTIONS"
        response.headers["Access-Control-Allow-Headers"] = "Content-Type, Authorization, Accept, X-Requested-With"
        response.headers["Access-Control-Allow-Credentials"] = "true"
        response.headers["Access-Control-Expose-Headers"] = "*"
        response.headers["Vary"] = "Origin"
        
        return response

# ê¸°ì¡´ ì—”ë“œí¬ì¸íŠ¸ë“¤ë„ ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
@router.get("/generate/{intent_id}")
async def generate_questions_legacy(
    intent_id: str, 
    current_user=Depends(get_current_user)
):
    """ê¸°ì¡´ GET ë°©ì‹ ì—”ë“œí¬ì¸íŠ¸ (í•˜ìœ„ í˜¸í™˜ì„±ìš©)"""
    logger.warning("Legacy GET endpoint used - please migrate to POST /generate")
    
    raise HTTPException(
        status_code=410,
        detail="ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” ë” ì´ìƒ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤. POST /questions/generateë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
    )